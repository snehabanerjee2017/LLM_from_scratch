{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "616854c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gpt_download import download_and_load_gpt2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f90d6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = 'data/the-verdict.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349d9598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of raw text: 20479 characters\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n"
     ]
    }
   ],
   "source": [
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "print(f\"Length of raw text: {len(raw_text)} characters\")\n",
    "print(raw_text[:100])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4913080e",
   "metadata": {},
   "source": [
    "#### Raw text to tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78514bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4670"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.;?_!\"()\\']|--|\\s)', raw_text) # split on commas, periods, question amrks, quotation marks, double dashes and whitespace\n",
    "preprocessed = [item for item in preprocessed if item.strip()] # remove whitespace-only tokens\n",
    "len(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be4d1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'HAD',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'genius',\n",
       " '--',\n",
       " 'though',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fellow',\n",
       " 'enough',\n",
       " '--',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'no',\n",
       " 'great',\n",
       " 'surprise',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'that',\n",
       " ',',\n",
       " 'in']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437de9a9",
   "metadata": {},
   "source": [
    "#### Token to Token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3843ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 1146 tokens\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(list(set(preprocessed)))\n",
    "vocab_size = len(all_words)\n",
    "print(f\"Vocab size: {vocab_size} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc79847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindle:', 43)\n",
      "('Grindles', 44)\n",
      "('HAD', 45)\n",
      "('Had', 46)\n",
      "('Hang', 47)\n",
      "('Has', 48)\n",
      "('He', 49)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token: integer for integer, token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    if i < 50:\n",
    "        print(item)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54f087",
   "metadata": {},
   "source": [
    "#### Text tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5f8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {integer: token for token, integer in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item for item in preprocessed if item.strip()]\n",
    "        token_ids = [self.str_to_int[token] for token in preprocessed]\n",
    "        return token_ids\n",
    "    \n",
    "    def decode(self, token_ids):\n",
    "        text = ' '.join([self.int_to_str[token_id] for token_id in token_ids])\n",
    "        text = re.sub(r'\\s+([,.;?_!\"()\\'])', r'\\1', text) # remove space before punctuation\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06317e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d236b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 57, 2, 861, 1002, 607, 536, 755, 5, 1142, 601, 5, 1, 68, 7, 38, 862]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\"It's the last he painted, you know,\" Mrs. Gisburn said\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5dc9962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" It' s the last he painted, you know,\" Mrs. Gisburn said\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80c74a",
   "metadata": {},
   "source": [
    "#### Tokenizer handles unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd4539c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token: integer for integer, token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "907c9841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14dd823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1143)\n",
      "('your', 1144)\n",
      "('yourself', 1145)\n",
      "('<|endoftext|>', 1146)\n",
      "('<|unk|>', 1147)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d227a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {integer: token for token, integer in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "\n",
    "        token_ids = [self.str_to_int[token] for token in preprocessed]\n",
    "        return token_ids\n",
    "    \n",
    "    def decode(self, token_ids):\n",
    "        text = ' '.join([self.int_to_str[token_id] for token_id in token_ids])\n",
    "        text = re.sub(r'\\s+([,.;?_!\"()\\'])', r'\\1', text) # remove space before punctuation\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4a277b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join([text1, text2])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72e02bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7bc7936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1147, 5, 357, 1142, 634, 989, 10, 1146, 56, 1002, 970, 998, 730, 1002, 1147, 7]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6584b9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d83faa",
   "metadata": {},
   "source": [
    "#### Byte Pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4205b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11475a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 286, 262, 20562, 13]\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\"\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c799afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ba4b3",
   "metadata": {},
   "source": [
    "#### Data sampling with sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8310151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of tokenized text: 5145 tokens\n"
     ]
    }
   ],
   "source": [
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(f\"Length of tokenized text: {len(enc_text)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17667b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c095a9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence (x): [290, 4920, 2241, 287]\n",
      "Target sequence (y):      [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size + 1]\n",
    "print(\"Input sequence (x):\", x)\n",
    "print(\"Target sequence (y):     \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d0c4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] -> 4920\n",
      "[290, 4920] -> 2241\n",
      "[290, 4920, 2241] -> 287\n",
      "[290, 4920, 2241, 287] -> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "\n",
    "    print(context, \"->\", desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31ca5889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ->  established\n",
      " and established ->  himself\n",
      " and established himself ->  in\n",
      " and established himself in ->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    \n",
    "\n",
    "    print(tokenizer.decode(context), \"->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0aea3",
   "metadata": {},
   "source": [
    "#### Dataset for batched inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4663f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1:i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e633ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(text, batch_size = 4, max_length = 256, stride = 128, shuffle = True, drop_last = True):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e859e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=4, stride=1, shuffle=False, drop_last=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0774ec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b134ac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False, drop_last=False)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"Targets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60169068",
   "metadata": {},
   "source": [
    "#### Token embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53ed997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2,3,5,1])\n",
    "vocab_size = 6\n",
    "output_dim = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "469a681a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed7675af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95553067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b2e9c",
   "metadata": {},
   "source": [
    "#### Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b45b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 256\n",
    "vocab_size = 50257  # GPT-2 vocabulary size\n",
    "token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfe68c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: \n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Inputs shape: torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "batch_size = 8\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=batch_size, max_length=max_length, stride=max_length, shuffle=False, drop_last=False)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token IDs: \\n\", inputs)\n",
    "print(\"Inputs shape:\", inputs.shape)  # Expected: (batch_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b94a577e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Embeddings shape: torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(\"Token Embeddings shape:\", token_embeddings.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "569bfc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positional Embeddings shape: torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(num_embeddings=context_length, embedding_dim=output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(\"Positional Embeddings shape:\", pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff3b4863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Embeddings shape: torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(\"Input Embeddings shape:\", input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca112ad2",
   "metadata": {},
   "source": [
    "#### Self attention without trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "805242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89], # Your\n",
    "     [0.55, 0.87, 0.66], # journey\n",
    "     [0.57, 0.85, 0.64], # starts\n",
    "     [0.22, 0.58, 0.33], # with \n",
    "     [0.77, 0.25, 0.10], # one\n",
    "     [0.05, 0.80, 0.55]] # step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfdc372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(query, x_i)\n",
    "\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcb1dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum:  tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum()\n",
    "print(\"Attention Weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum: \", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a74adc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights (naive softmax): tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(\"Attention Weights (naive softmax):\", attn_weights_2_naive)\n",
    "print(\"Sum: \", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2512f8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights (torch.softmax): tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention Weights (torch.softmax):\", attn_weights_2)\n",
    "print(\"Sum: \", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2b7b32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector: tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "\n",
    "print(\"Context Vector:\", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06b00846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores Matrix:\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6,6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i,j] = torch.dot(x_i, x_j)\n",
    "\n",
    "# for loops are slower, matric multiplication does the same thing more efficiently\n",
    "print(\"Attention Scores Matrix:\\n\", attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8064aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores Matrix (using @ operator):\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(\"Attention Scores Matrix (using @ operator):\\n\", attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1f60912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights Matrix:\n",
      " tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "print(\"Attention Weights Matrix:\\n\", attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46f45a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edbe586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Context Vectors:\n",
      " tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(\"All Context Vectors:\\n\", all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "686e2b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Context Vectors:\n",
      " tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous Context Vectors:\\n\", context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561697ad",
   "metadata": {},
   "source": [
    "#### Self attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a21c613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2ffb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False) # requires_grad=False since we are not training\n",
    "W_key = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.randn(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efaf3b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Vector:\n",
      " tensor([-1.1729, -0.0048])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(\"Query Vector:\\n\", query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f3ea9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys shape:\n",
      " torch.Size([6, 2])\n",
      "Values shape:\n",
      " torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"Keys shape:\\n\", keys.shape)\n",
    "print(\"Values shape:\\n\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffeb333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores (Query 2 vs Key 2):\n",
      " tensor(0.1376)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_scores_22 = query_2.dot(keys_2)\n",
    "print(\"Attention Scores (Query 2 vs Key 2):\\n\", attn_scores_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "baf1233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Scores (Query 2 vs All Keys):\n",
      " tensor([ 0.2172,  0.1376,  0.1730, -0.0491,  0.7616, -0.3809])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T\n",
    "print(\"Attention Scores (Query 2 vs All Keys):\\n\", attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f6c0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights (Query 2 vs All Keys):\n",
      " tensor([0.1704, 0.1611, 0.1652, 0.1412, 0.2505, 0.1117])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim=-1)\n",
    "print(\"Attention Weights (Query 2 vs All Keys):\\n\", attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d34e138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector (Query 2):\n",
      " tensor([0.2854, 0.4081])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(\"Context Vector (Query 2):\\n\", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7631dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV1(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(SelfAttentionV1, self).__init__()\n",
    "        self.W_query = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_key = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "        self.W_value = torch.nn.Parameter(torch.randn(d_in, d_out))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        queries = inputs @ self.W_query\n",
    "        keys = inputs @ self.W_key\n",
    "        values = inputs @ self.W_value\n",
    "\n",
    "        d_k = keys.shape[-1]\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / d_k**0.5, dim=-1)\n",
    "\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74e9788c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2845, 0.4071],\n",
      "        [0.2854, 0.4081],\n",
      "        [0.2854, 0.4075],\n",
      "        [0.2864, 0.3974],\n",
      "        [0.2863, 0.3910],\n",
      "        [0.2860, 0.4039]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttentionV1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e438218",
   "metadata": {},
   "source": [
    "#### Self attention using Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0be7658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionV2(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super(SelfAttentionV2, self).__init__()\n",
    "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1], dim=-1)\n",
    "\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9904b421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0748,  0.0699],\n",
      "        [-0.0755,  0.0693],\n",
      "        [-0.0755,  0.0692],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0766,  0.0675],\n",
      "        [-0.0759,  0.0685]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttentionV2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d96073",
   "metadata": {},
   "source": [
    "#### Causal attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a298f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights:\n",
      " tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(\"Attention weights:\\n\", attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69b8f262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal Mask:\n",
      " tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones((context_length, context_length)))\n",
    "print(\"Causal Mask:\\n\", mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b2817f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Attention Weights:\n",
      " tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights * mask_simple\n",
    "print(\"Masked Attention Weights:\\n\", masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "201ea235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Masked Attention Weights:\n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(\"Normalized Masked Attention Weights:\\n\", masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a2ad8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Attention Scores:\n",
      " tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = torch.triu(torch.ones((context_length, context_length)), diagonal=1).bool()\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(\"Masked Attention Scores:\\n\", masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f960b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Attention Weights:\n",
      " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=-1)\n",
    "print(\"Masked Attention Weights:\\n\", attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d766f2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vectors with Causal Masking:\n",
      " tensor([[ 0.1196, -0.3566],\n",
      "        [ 0.2501,  0.0845],\n",
      "        [ 0.2996,  0.2571],\n",
      "        [ 0.2913,  0.3103],\n",
      "        [ 0.2869,  0.3839],\n",
      "        [ 0.2830,  0.3669]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "context_vec = attn_weights @ values\n",
    "print(\"Context Vectors with Causal Masking:\\n\", context_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76141455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(p=0.5)\n",
    "example = torch.ones(6,6)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5d25035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6e058",
   "metadata": {},
   "source": [
    "#### Casual Attention Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1ffb1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "batch = torch.stack([inputs, inputs], dim=0)\n",
    "print(batch.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60c366b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasualAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, qkv_bias=False, dropout=0.1):\n",
    "        super(CasualAttention, self).__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1,2)\n",
    "\n",
    "        attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vectors = attn_weights @ values\n",
    "        return context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d24ac647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vecs shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CasualAttention(d_in, d_out, context_length=context_length, dropout=0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"Context vecs shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19dc179",
   "metadata": {},
   "source": [
    "#### Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62fc38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout, qkv_bias=False):\n",
    "        super(MultiHeadAttentionWrapper, self).__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "        self.heads = torch.nn.ModuleList([\n",
    "            CasualAttention(d_in, d_out, context_length, qkv_bias, dropout)\n",
    "            for _ in range(num_heads)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([head(x) for head in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e2acc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vecs shape: torch.Size([2, 6, 4])\n",
      "Context vecs: tensor([[[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]],\n",
      "\n",
      "        [[-0.4519,  0.2216,  0.4772,  0.1063],\n",
      "         [-0.5874,  0.0058,  0.5891,  0.3257],\n",
      "         [-0.6300, -0.0632,  0.6202,  0.3860],\n",
      "         [-0.5675, -0.0843,  0.5478,  0.3589],\n",
      "         [-0.5526, -0.0981,  0.5321,  0.3428],\n",
      "         [-0.5299, -0.1081,  0.5077,  0.3493]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "d_in, d_out = 3, 2\n",
    "mha = MultiHeadAttentionWrapper(d_in, d_out, num_heads=2, context_length=context_length, dropout=0.0)\n",
    "context_vecs = mha(batch)\n",
    "print(\"Context vecs shape:\", context_vecs.shape)\n",
    "print(\"Context vecs:\", context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f3ecd9",
   "metadata": {},
   "source": [
    "#### Efficient Multi-head Attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "842334cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias=False):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_out % num_heads == 0\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.out_proj = torch.nn.Linear(d_out, d_out)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1,2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1,2).contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "285031a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context vecs shape: torch.Size([2, 6, 2])\n",
      "Context vecs: tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length=context_length, num_heads=2, dropout=0.0)\n",
    "context_vecs = mha(batch)\n",
    "print(\"Context vecs shape:\", context_vecs.shape)\n",
    "print(\"Context vecs:\", context_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233ae3d",
   "metadata": {},
   "source": [
    "#### GPT from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf2f35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"n_layers\": 12,\n",
    "    \"n_heads\": 12,\n",
    "    \"emb_dim\": 768,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f538c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(DummyTransformerBlock, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d9e3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPTModel(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(DummyGPTModel, self).__init__()\n",
    "        self.tok_emb = torch.nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = torch.nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = torch.nn.Dropout(p=cfg[\"drop_rate\"])\n",
    "        self.trf_blocks = torch.nn.Sequential(*[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = torch.nn.LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = torch.nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1))\n",
    "        x = self.drop_emb(tok_embeds + pos_embeds)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "51ef4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLayerNorm(torch.nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super(DummyLayerNorm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b81310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eb952cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "Output: tensor([[[-0.7867,  0.2203, -0.4508,  ..., -0.9936, -0.1412, -0.2999],\n",
      "         [-0.0788,  0.3004, -0.2935,  ...,  0.1583,  0.8917,  0.8230],\n",
      "         [ 0.3708,  1.1126, -0.3226,  ...,  0.8023, -0.0038,  0.3935],\n",
      "         [ 0.0636,  1.0572, -0.2507,  ...,  0.7542, -0.0750, -0.6896]],\n",
      "\n",
      "        [[-0.7208,  0.1351, -0.6014,  ..., -1.0272,  0.1729, -0.2920],\n",
      "         [-0.5938,  0.4453, -0.0059,  ...,  0.3414,  0.0572,  1.0986],\n",
      "         [ 0.2675,  0.8407, -0.4476,  ..., -0.0181, -0.1090,  0.2541],\n",
      "         [-0.1035, -0.5901, -0.3932,  ...,  1.4022, -0.3188,  0.1304]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(\"Output:\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f816843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5)\n",
    "layer = torch.nn.Sequential(torch.nn.Linear(5,6), torch.nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ff556d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1,keepdim=True)\n",
    "var = out.var(dim=-1,keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "50586438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Output:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean after normalization:\n",
      " tensor([[-5.9605e-08],\n",
      "        [ 1.9868e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance after normalization:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1,keepdim=True)\n",
    "var = out_norm.var(dim=-1,keepdim=True)\n",
    "print(\"Normalized Output:\\n\", out_norm)\n",
    "print(\"Mean after normalization:\\n\", mean)\n",
    "print(\"Variance after normalization:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad225f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a11e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(torch.nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = torch.nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = torch.nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * x_norm + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6abd4d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean after LayerNorm:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance after LayerNorm:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "mean = out_ln.mean(dim=-1,keepdim=True)\n",
    "var = out_ln.var(dim=-1,keepdim=True, unbiased=False)\n",
    "print(\"Mean after LayerNorm:\\n\", mean)\n",
    "print(\"Variance after LayerNorm:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f644ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GELU, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24c81a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gelu, relu = GELU(), torch.nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, steps=100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8,3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"])):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.plot(x,y, label=label)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5cf06e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            torch.nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "20c73b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.randn(2, 3, 768)\n",
    "out = ffn(x)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "adbb46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super(ExampleDeepNeuralNetwork, self).__init__()\n",
    "\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(torch.nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            torch.nn.Sequential(torch.nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            torch.nn.Sequential(torch.nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),  \n",
    "            torch.nn.Sequential(torch.nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            torch.nn.Sequential(torch.nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(x)\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0ed5fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8cfea961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    loss = torch.nn.MSELoss()(output, target)\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd18bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0e8d3664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut=True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "891fbea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"]\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = torch.nn.LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = torch.nn.LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_resid = torch.nn.Dropout(p=cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_resid(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c3f30801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.randn(2, 4, 768)\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "479f60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(torch.nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(GPTModel, self).__init__()\n",
    "        self.tok_emb = torch.nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = torch.nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = torch.nn.Dropout(p=cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = torch.nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        self.final_norm = torch.nn.LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = torch.nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1))\n",
    "        x = self.drop_emb(tok_embeds + pos_embeds)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b2fc784f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "Output:\n",
      " tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "out = model(batch)\n",
    "print(\"Input batch\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(\"Output:\\n\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0e6fe02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the model: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters in the model: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0440be12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Token embeddinng layer shape: torch.Size([50257, 768])\n",
      " Output head layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\" Token embeddinng layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\" Output head layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "85f339f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in GPT-2 with weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.tok_emb.parameters())\n",
    "print(f\"Total number of parameters in GPT-2 with weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a6b54988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model size (float32): 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4\n",
    "total_size_mb = total_size_bytes / (1024 ** 2)\n",
    "print(f\"Total model size (float32): {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "af19809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        logits = logits[:, -1, :]\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ec3ddf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: [15496, 11, 314, 716]\n",
      "Encoded input tensor shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"Encoded input:\", encoded)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0) \n",
    "print(\"Encoded input tensor shape:\", encoded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40dbcc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267]])\n",
      "Output length: 10\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = encoded_tensor,\n",
    "    max_new_tokens = 6,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output:\", out)\n",
    "print(\"Output length:\", len(out[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3b89b2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Hello, I am Featureiman Byeswickattribute argue\n"
     ]
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "print(\"Generated text:\\n\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "45c3c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"n_layers\": 12,\n",
    "    \"n_heads\": 12,\n",
    "    \"emb_dim\": 768,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9342cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3ed80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    return tokenizer.decode(token_ids.squeeze(0).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "922640f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b0d53691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      " Every effort moves you Aeiman Byeswickattributeometer inspector Normandy freezerigrate\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens = 10,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Generated text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46da1741",
   "metadata": {},
   "source": [
    "#### Text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e8cd33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], # [every effort moves]\n",
    "                       [40, 1107, 588]]) #[\"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "93b71c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345], # [effort moves you]\n",
    "                        [588, 428, 11311]])  # [really like chocolate]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6a61f16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probas shape: torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probas shape:\", probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5d5f26b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token IDs:\n",
      " tensor([[[36397],\n",
      "         [39619],\n",
      "         [20610]],\n",
      "\n",
      "        [[ 8615],\n",
      "         [49289],\n",
      "         [47105]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Predicted token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "44545529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Gathering SerbianFriday\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(start_dim=0), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "12d9b57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target probabilities batch 1: tensor([2.3466e-05, 2.0531e-05, 1.1733e-05])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=True)\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Target probabilities batch 1:\", target_probas_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "08b9a8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target probabilities batch 1: tensor([1.3380e-05, 1.3445e-05, 1.1586e-05])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Target probabilities batch 1:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0db6f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities of target tokens: tensor([-10.6600, -10.7936, -11.3531, -11.2217, -11.2169, -11.3658])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "log_probas = torch.log(torch.cat([target_probas_1, target_probas_2], dim=0))\n",
    "print(\"Log probabilities of target tokens:\", log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9a80e02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log probability of target tokens: tensor(-11.1018)\n"
     ]
    }
   ],
   "source": [
    "avg_log__probas = torch.mean(log_probas)\n",
    "print(\"Average log probability of target tokens:\", avg_log__probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b231bef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative average log probability (Cross-Entropy Loss): tensor(11.1018)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log__probas * -1\n",
    "print(\"Negative average log probability (Cross-Entropy Loss):\", neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646fe688",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "68f6e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([2, 3, 50257])\n",
      "targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"logits shape:\", logits.shape)\n",
    "print(\"targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c6eb0b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits shape: torch.Size([6, 50257])\n",
      "Flattened targets shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(start_dim=0, end_dim=1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits shape:\", logits_flat.shape)\n",
    "print(\"Flattened targets shape:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8be6a728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy Loss: tensor(11.1018)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Cross-Entropy Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762f722",
   "metadata": {},
   "source": [
    "#### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d47919b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: tensor(66292.8359)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908bd716",
   "metadata": {},
   "source": [
    "#### Training with variable lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9b63fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ac704ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in text: 20479\n",
      "Total tokens in text: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Total characters in text: {total_characters}\")\n",
    "print(f\"Total tokens in text: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "76ae831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "86ff28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dc11b0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n",
      "Validation loader:\n",
      "Input batch shape: torch.Size([2, 256])\n",
      "Target batch shape: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(\"Input batch shape:\", x.shape)\n",
    "    print(\"Target batch shape:\", y.shape)\n",
    "\n",
    "print(\"Validation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(\"Input batch shape:\", x.shape)\n",
    "    print(\"Target batch shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "429c46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(start_dim=0, end_dim=1),\n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0670aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "98ef4a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Train Loss: 10.9885\n",
      "Validation Loss: 10.9903\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model.to(device)\n",
    "train_loss = calc_loss_loader(train_loader, model, device)\n",
    "val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(f\"Train Loss: {train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "36af1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0d6858ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model = model,\n",
    "            idx = encoded,\n",
    "            max_new_tokens = 50,\n",
    "            context_size = context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a3ab3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                model.eval()\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Epoch {epoch+1}, Step {global_step:06d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        \n",
    "        generate_and_print_sample(model, train_loader.dataset.tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a63f3782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 000000: Train Loss = 9.8964, Val Loss = 9.9327\n",
      "Epoch 1, Step 000005: Train Loss = 7.9162, Val Loss = 8.3380\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Epoch 2, Step 000010: Train Loss = 6.8458, Val Loss = 7.0472\n",
      "Epoch 2, Step 000015: Train Loss = 5.9962, Val Loss = 6.6160\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Epoch 3, Step 000020: Train Loss = 5.6618, Val Loss = 6.6073\n",
      "Epoch 3, Step 000025: Train Loss = 5.3515, Val Loss = 6.3413\n",
      "Every effort moves you, and I had been.                                            \n",
      "Epoch 4, Step 000030: Train Loss = 4.0013, Val Loss = 6.2778\n",
      "Epoch 4, Step 000035: Train Loss = 2.5330, Val Loss = 6.2245\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Epoch 5, Step 000040: Train Loss = 3.8244, Val Loss = 6.1617\n",
      "Every effort moves you know it was not that the picture--I had the fact with the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Epoch 6, Step 000045: Train Loss = 2.5056, Val Loss = 6.1765\n",
      "Epoch 6, Step 000050: Train Loss = 2.9911, Val Loss = 6.1445\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a and he was no I had the fact, and in the picture.                    \n",
      "Epoch 7, Step 000055: Train Loss = 2.5567, Val Loss = 6.1361\n",
      "Epoch 7, Step 000060: Train Loss = 1.7366, Val Loss = 6.2380\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Epoch 8, Step 000065: Train Loss = 0.9426, Val Loss = 6.2411\n",
      "Epoch 8, Step 000070: Train Loss = 1.4724, Val Loss = 6.2448\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Epoch 9, Step 000075: Train Loss = 0.7792, Val Loss = 6.2955\n",
      "Epoch 9, Step 000080: Train Loss = 0.6212, Val Loss = 6.4002\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, my eye fell on a small picture\n",
      "Epoch 10, Step 000085: Train Loss = 0.3896, Val Loss = 6.4598\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.01)\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=1,\n",
    "    start_context=\"Every effort moves you\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "013e06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label='Train Loss')\n",
    "    ax1.plot(epochs_seen, val_losses, label='Validation Loss', linestyle='-.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel('Tokens Seen')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "961f27f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUG1JREFUeJzt3QdcldUbB/AfG0FABBURRXErihu3GeY2V9owZ2mOHA1LU8vKnGX9tbJhaaWmaa5cOXIv3Bv3QkEUUJYgwv1/nnO9l4uiAnK5l8vv+/m8cvd77uu993nPOc85x0qj0WhAREREZsna1AUgIiKix2OgJiIiMmMM1ERERGaMgZqIiMiMMVATERGZMQZqIiIiM8ZATUREZMYYqImIiMwYAzUREZEZY6AmyuMuXboEKysrHD582NRFISIjYKAmMgMSaJ+0jR8/HnnJzZs3MWjQIJQqVQoODg7w8vJCq1atsHPnTlMXjSjPsTV1AYgICAsL0x+GRYsW4eOPP8bp06f1txUsWDBPHaauXbvi3r17+O233+Dn54cbN25g06ZNiIyMNHXRiPIc1qiJzIDUOHWbm5ubqkXrrhctWhTTp0+Hj4+Pqp3WqFED69ate+xrpaSkoF+/fqhUqRKuXLmibluxYgVq1aoFR0dHFTg//fRT3L9/X/8c2d/s2bPRuXNnODk5oXz58li5cqX+/ujoaPTo0QNFihRBgQIF1P1z5szJcP+3b9/G9u3bMWXKFDRv3hy+vr6oV68eRo8ejRdffDHd49588031mq6urnj++edx5MiRdK/1rOUmsgiyehYRmY85c+Zo3Nzc9NenT5+ucXV11fz555+akJAQzQcffKCxs7PTnDlzRt1/8eJFWQFPc+jQIU1iYqKmc+fOmpo1a2oiIiLU/du2bVPPnzt3rub8+fOa9evXa0qXLq0ZP368fh/yfB8fH82CBQs0Z8+e1QwbNkxTsGBBTWRkpLp/yJAhmho1amj27dun9rdhwwbNypUrMyx/cnKyeu6IESNUeR6nRYsWmg4dOqjXlPfy3nvvaTw8PPT7zIlyE1kCBmoiMw/U3t7emi+++CLdY+rWrasZPHhwukC9fft2TVBQkKZx48aa27dv6x8rt02cODHd8//44w9N8eLF9dfl+WPHjtVfj4uLU7etXbtWXZeA2rdv30y/hyVLlmjc3d01jo6OmoYNG2pGjx6tOXLkiP5+KasE4YcDedmyZTU//vhjjpWbyBKw6ZvIjMXExOD69eto1KhRutvl+qlTp9Ld9uqrryI+Ph7r169Xzec60pz82WefqX5u3da/f3/VL56QkKB/XPXq1fWXnZ2dVXN0RESEui6JYQsXLlTN7h988AF27dr11D5qKbc0Q7du3RpbtmxRTdhz587VlykuLg4eHh7pynXx4kWcP38+x8pNZAmYTEZkIdq2bYt58+Zh9+7dqr9XRwKi9O126dLlkedI36+OnZ1duvuk/zc1NVVdbtOmDS5fvow1a9Zgw4YNCAoKwpAhQ/Dll18+tjzy2i+88ILaxo0bp/qjP/nkE/Tp00eVqXjx4iqAP6xQoUI5Vm4iS8BATWTGpHbo7e2thjU1a9ZMf7tclwQtQ1Lr9ff3Vwlbq1ev1j9earKSQV6uXLlnKoskffXu3VttTZo0wciRI58YqB9WpUoVLF++XF+m8PBw2NraonTp0hk+PqfKTZTXMVATmTkJiFITLVu2rGp6lmxrmdxk/vz5jzx26NChKuu7ffv2WLt2LRo3bqyGesl1GdP80ksvwdraWjUrHz9+HBMmTMhUGeQ1ateujapVqyIpKQmrVq1C5cqVM3ysDMHq1q2byjyXZmkXFxfs378fU6dORceOHdVjWrRogQYNGqBTp07q9goVKqimcjnBkAzuOnXq5Ei5iSwBAzWRmRs2bBju3LmD9957T/W9Ss1U+n5lKFJGRowYoZp+pSlchnHJRCMSWKW/V4ZMSVOxDN2SpujMsre3V8OrZBY0GZ4lNWrps86I9CUHBgbi66+/Vv3NycnJKFmypOpf/uijj/TN09KMPmbMGPTt21dNkCJD0Zo2bYpixYqpx+REuYksgZVklJm6EERERJQxZn0TERGZMQZqIiIiM8ZATUREZMYYqImIiMwYAzUREZEZY6AmIiIyYwzUj/Hdd9+pGZNkqkIZExocHJy7/zNmatu2bejQoYOaLUvGwupmmtKR0X4yUYVMDynjbWVii7Nnz6Z7TFRUlFoyUWbdkuki33jjDTVdpKGjR4+qsbpy/GUMrkyK8bDFixercbXymGrVqqlxuXnZpEmTULduXTVBiCxtKZOBGK5JLRITE9XUnbo5smVObVnr2ZAsbdmuXTu17KO8jkyYYrg0pNDNvS3LZsrMX7o5uC39OzBr1iw1CYt89mSTSVdkYhgdHt+cNXnyZPU7IWP7eYyfgalXBTFHCxcu1Njb22t+/fVXzYkTJzT9+/fXFCpUSHPjxg1NfrdmzRrNmDFjNEuXLlWrFC1btizd/ZMnT1YrPy1fvlytlvTiiy9qypQpo7l7967+Ma1bt9YEBARo9uzZo1ZRKleunObVV1/V33/nzh1NsWLFND169NAcP35cLe9YoEAB/apKYufOnRobGxvN1KlTNSdPnlQrKMnSj8eOHdPkVa1atVIrZ8l7Pnz4sKZt27aaUqVKqRWhdAYOHKgpWbKkZtOmTZr9+/dr6tevr1an0rl//77G399fLSEpy17K/5enp6davUrnwoULGicnJ827776rjt3MmTPVsVy3bp3Ffwdkac7Vq1erZTVPnz6t+eijj9TnRo654PHNOcHBwWpZ0urVq2uGDx+uv53HOOsYqDNQr149tf6uTkpKilpqcNKkSdk4xJbr4UCdmpqq8fLy0kybNk1/myy36ODgoIKtkMAgz5M1iHVkSUIrKyvNtWvX1PXvv/9eLZGYlJSkf8yHH36oqVixov569+7dNe3atUtXnsDAQM1bb72lsRSynrQcq61bt+qPpQSVxYsX6x9z6tQp9Zjdu3er6xKYra2tNeHh4frHzJo1Sy0pqTuesp511apV0+3r5ZdfVicK+fE7IJ+12bNn8/jmoNjYWE358uXVuuXNmjXTB2p+hrOHTd8PuXfvHg4cOKCabHVkjmG5LqsS0ePJEoWy0ILhsZPlFqXZVHfs5K80d8tczjryeDnGe/fu1T9GppKUaSt1ZDpJaQaOjo7WP8ZwP7rHWNL/kUwbKgoXLqz+yudSpuM0fN/S9C9zYRseX+kG0E3DqTsuslzmiRMnMnXs8st3QOZEl2lQZWlQaQLn8c050j0j3S8Pf854jLOHc30/5NatW+oLbPhDJ+R6SEhINg9z/iBBWmR07HT3yV/pNzUkKyhJMDJ8TJkyZR55Dd197u7u6u+T9pPXyVzd0q8n607LilhC3pucvOiWgXzc8c3ouOjue9JjJJjfvXtXnQxZ8nfg2LFjKjBLf7T08y9btkzNny4LnfD4Pjs5+Tl48CD27dv3yH38DGcPAzWRmdZIZJWoHTt2mLooFqdixYoqKEuLxZIlS9SynVu3bjV1sSzC1atXMXz4cLVmueGa4fRs2PT9EE9PT9jY2DySSSvXZXUfejzd8XnSsZO/sgKUIclIlkxww8dk9BqG+3jcYyzh/+jtt99Wq0Zt3rwZPj4++tvlvUmz9O3bt594fLN77CQLWjL1Lf07ILVmyXSXZTsl0z4gIAD/+9//eHxzgDRty/dbRhRIS5lschI0Y8YMdVlaZfgZzjoG6gy+xPIF3rRpU7pmSLkuzWX0eNJcLT/khsdOmlOl71l37OSvBBr5Quv8999/6hhLX7buMTIMTPpjdeQMXWpC0uyte4zhfnSPycv/R5KfJ0FammLlmDzc/C+fS1nq0fB9S7+9DMcyPL7StGt4MiTHRYKwNO9m5tjlt++AvDdZY5vH99kFBQWpz5+0WOg2yUeR4Zi6y/wMZ0M2k9AsmgxNkUzluXPnqizlAQMGqKEphpm0+ZVkc8qwH9nk4zN9+nR1+fLly/rhWXKsVqxYoTl69KimY8eOGQ7Pqlmzpmbv3r2aHTt2qOxQw+FZkhkqw7N69uyphs3I/4cMJ3p4eJatra3myy+/VJnPn3zySZ4fnjVo0CA1tG3Lli2asLAw/ZaQkJBuaIsM2frvv//U8KwGDRqo7eHhWS1btlRDvGTIVZEiRTIcnjVy5Eh17L777rsMh2dZ4ndg1KhRKov+4sWL6vMp12XEwfr169X9PL45zzDrm8c4exioH0PGlsoPoowllaEqMuaXNJrNmzerAP3w1rt3b/0QrXHjxqlAKz/0QUFBaryqocjISBWYCxYsqIYN9e3bV50AGJIx2I0bN1avUaJECXUC8LC//vpLU6FCBfV/JMONZHxsXpbRcZVNxlbryAnP4MGD1ZAiCbadO3dWwdzQpUuXNG3atFFjz2UM9XvvvadJTk5+5P+xRo0a6tj5+fml24clfwf69eun8fX1Ve9JTmDk86kL0oLH1/iBmsc466zkn+zUxImIiMj42EdNRERkxhioiYiIzBgDNRERkRljoCYiIjJjDNRERERmjIGaiIjIjDFQP4HMVjR+/Hj1l3Iej69x8fgaH48xj29u4DjqJ5DpL2WZRpm8X6ZgpJzF42tcPL7Gx2PM45sbWKMmIiIyYwzUREREZszi16OWJRQPHTqkllezts7aeUlsbKz6e+3aNdXERTmLx9e4eHyNj8eYx/dZVm2TpWNr1qyplgB9Eovvo963bx/q1atn6mIQERE9Ijg4GHXr1kW+rlFLTVp3MIoXL27q4hARESEsLExVInUxKl8Hal1ztwRpHx8fUxeHiIhILzNdsiZNJtu2bRs6dOgAb29vWFlZYfny5enul1b5jz/+WAXZAgUKoEWLFjh79qzJyktERJTbTBqo4+PjERAQgO+++y7D+6dOnYoZM2bghx9+wN69e+Hs7IxWrVohMTEx18tKRERkCiZt+m7Tpo3aMiK16W+++QZjx45Fx44d1W2///67as+Xmvcrr7ySy6UlIiLKfWbbR33x4kWEh4er5m4dmSUsMDAQu3fvZqAmohwbJnPv3j0eTcpRdnZ2sLGxsexALUFaPJwRJ9d19z1u7l3Dubl14xxzitT0pT+diPI+CdBSKZBgTZTTChUqBC8vr2eOGWYbqLNr0qRJ+PTTT3P8dVNSNfhtxzkU2TsFbTu+DJsKL+T4Pogo98hJtwyRkVpPyZIlszwhEtGTPlsJCQmIiIhQ1591aLDZBmo5CxEyc4vhm5TrNWrUeOzzRo8ejXfffVd/XWYVq1KlyjOXJzI+CTc3zUQ/q8VI+msdbAZvAwr7PfPrEpHpZi2UH1MZdeLk5MT/BspRMlJJSLAuWrToMzWDm+0pZJkyZVSw3rRpk/42mcZTsr8bNGjw2Oc5ODiola50m4uLS46Up6iLI3xbDcOh1HJwuB+Le/NfBZLicuS1iSj3paSkqL/29vY8/GQUuhPA5OTkZ3odkwbquLg4HD58WG1C+ork8pUrV1Sb/ogRIzBhwgSsXLkSx44dQ69evdTZb6dOnUxS3u71y+JHr/GI0BSCfWQINCvfljYOk5SFiHIGc07I3D9bJg3U+/fvVxOSyyakyVouyyQn4oMPPsDQoUMxYMAANReqBPZ169bB0dHRJOW1trbCB92aY1jKO0jW2MDqxDJg5/9MUhYiIsofTBqon3vuOdXp/vA2d+5c/dnIZ599prK8ZZKTjRs3okKFCqYsMvyKFETTFu3x6f1e6rpm06fAubTmeSKivKZ06dJq3goyT2bbR23O+jfxw8EiXbDw/nOw0qQCS/oBURdNXSwisnBSeXnSNn78+GyvMigtl89a8ZLuSsp5Zpv1bc7sbKwxtVsAun3XF5VSr6JG4nlg0evAG+sBe2dTF4+ILJQMJ9NZtGiR6iY8ffq0/raCBQvqL0vrpCTMPW2tY1GkSBEjlJZyCmvU2eRfwg29GlfEwHsjEAU34MZxYAWTy4jIeGQkjG6TmRqlFq27HhISoka5rF27FrVr11YjYHbs2IHz58+raZhlsigJ5JLvI92IT2r6ltedPXs2OnfurDKXy5cvr5J6n8Xff/+NqlWrqnLJ/r766qt093///fdqP5KDJGV96aWX9PctWbIE1apVU0OePDw81IyVslZEfsFA/QxGtKgAB4+SeCtpOFJgA5xYCuyamXP/O0SUu5NU3Ltvkk32nVNGjRqFyZMn49SpU6hevbpKwm3btq0a6nro0CG0bt1arVooo2ueRCaO6t69O44ePaqe36NHD0RFRWWrTAcOHFCvJWs0yAgeaaIfN26cPh9JEouHDRumcpKkhUCShps2bapvRXj11VfRr18/9Z62bNmCLl265OgxM3ds+n4GBextMKlLNbz2cwLGJ/fE53ZzgW3TgJqvA06Fc+5/iYiM7m5yCqp8/K9JjvTJz1rByT5nfo4l2L3wQtrMiYULF1arFOp8/vnnWLZsmaohv/322499nT59+qgAKSZOnKhWMgwODlaBPqumT5+OoKAgFZyFJAWfPHkS06ZNU/uRkwZZHbF9+/aqVcDX11c/GigsLExNTiPBWW4XUrvOT1ijfkYNy3ri5Tol8UfKC5hn3w1JPVczSBORydSpUyfddalRv//++6hcubKae1qav6Vm+rQatdTGdSSIygRSuikxs0r216hRo3S3yfWzZ8+qfnQ5sZAg7Ofnh549e2L+/Plq1jgREBCggrwE527duuHnn39GdHQ08hPWqHPAR20r47/TERgb0xnhJxzwvk9OvCoR5aYCdjaqZmuqfecUCaqGJEhv2LABX375JcqVK6f6eaX/92krhsnqT4ak39pYi5dILfrgwYOqWXv9+vUqSU6axyUbvVChQqr8u3btUvfNnDkTY8aMUbNUygyW+QFr1DnAzckOn3esqi7/sPU8ToXFAFf2Ams/5MxlRHmEBCJpfjbFZszZ0Xbu3KmalyUxTGqlknh26dIl5CapzUs5Hi6XNIHr5sCW7HRJEps6darqF5cy/vfff+o+OT5SA5d+c+lnl2lfpfk+v2CNOoe09i+OVlWL4d8TNzBx8Xb8HvsmrJITgGJVgVrayVGIiHKbZFIvXbpUJZBJwJN+YmPVjG/evKmfElpHFlV67733VLa59I+//PLL2L17N7799luV6S1WrVqFCxcuqAQyd3d3rFmzRpWxYsWKquYsiXAtW7ZUi1vIddmPBP/8goE6B33W0R+7zkdi+/X72F19KBrahgBVu+TkLoiIspzIJRnTDRs2hKenJz788EO1wJExLFiwQG2GJDiPHTsWf/31l2rSlusSvCXpTWr6Qpq35WRCmrtlFko5ufjzzz/VcK5Tp05h27ZtaviYlFv6smVoV5s2bZBfWGksPMc9NDRUrTV79epV+PgYv/N4YfAVjFp6DI52Vlg/vBlKeXICFCJzJAFBFgKSfk5TrR9A+fczFpqF2MQ+6hz2ct2SqO9XGInJGny0/Lh2rJ9sB38H7mmzGImIiDKLgTqHSR/Q5C7V4WBrjR3nbmHJgVBg9XvAyqHAP8OYXEZERFnCQG0EpT2d8c4L2lW+Jqw+hdt+HQArG+DYYmCPNnmCiIgoMxiojeTNxmVQ1dsVd+4mY8xhN6DVRO0d68cBF7Yaa7dERGRhGKiNxNbGGlO6VoeNtRVWHw3DBpdOQMCrgCYFWNwHiL5srF0TEZEFYaA28gpbsna1GLviOGJaTAWK1wDuRgGLejC5jIiInoqB2shGtCiP0h5OuBGThCkbLwMvzwOcPIHwY8A/w5lcRkRET8RAbWSOdrLClnZy+/l7r2BvlBPQbe6D5LK/gD2zjF0EIiLKwxioc0GDsh54tV5JdXn00mNI9GkItPpCe+f6scDFbblRDCIiyoMYqHPJqDaVUdTFARduxWPmf2eBwIFA9VfSkstuP3nJOSKinPLcc89hxIgR+uulS5dWU3Q+bY6I5cuXP/O+c+p18hMG6lziVsBOzQUuftx6ASfDYoEO3wDFA4CESGBxX/ZXE9ETycIarVu3zvC+7du3qyAoK09llSwnOWDAgBw9+jJvd40aNR65PSwszOjzdM+dO1fNH24pGKhzUWt/L7Tx98L9VA0+/Pso7ls7aJPLilYBWn4up5q5WRwiymPeeOMNtTazzBP9sDlz5qBOnTqoXl2bE5MVRYoUgZOTE3KDLLPp4OCQK/uyFAzUuezTjlXh6miLY9fu4NedF4FCpYCBOwHfhrldFCLKY9q3b6+CqtQYDcXFxWHx4sUqkEdGRuLVV19FiRIlVPCVNahlJaonebjp++zZs2rJSVlIokqVKurk4GGyCpesJy378PPzU8tnJicnq/ukfLJ29JEjR1QtXzZdmR9u+j527Bief/55FChQAB4eHqpmL+9Hp0+fPujUqRO+/PJLteqWPGbIkCH6fWXHlStX0LFjRxQsWBCurq7o3r07bty4ob9fyt28eXO4uLio+2vXro39+/er+y5fvqxaNmQ5TmdnZ7XClyzLaUxc5jKXFXVxxJh2lfHh38cwfcMZtKrqBV8PgxW2rh8CjiwEWk0CrHkeRZTr7sVn/Tk2DoDNg5/TlPtAShJgZQ3YFXj669pnfoU9W1tb9OrVSwW9MWPGqKAnJEinpKSoAC1BTgKLBFIJMqtXr0bPnj1RtmxZ1KtX76n7kHWgu3TpgmLFiqm1n+/cuZOuP1tHgpiUw9vbWwXb/v37q9s++OADteb08ePHsW7dOmzcuFE93s3N7ZHXiI+PR6tWrdCgQQPV/B4REYE333wTb7/9drqTkc2bN6sgLX/PnTunXl+a1WWfWSXvTxekt27divv376vAL6+5ZcsW9ZgePXqgZs2amDVrFmxsbNQa23Z2duo+eey9e/fU0psSqE+ePKleK98GavngST/HvHnzEB4erj4QcnYla5vqPqB5Ufc6JbHi8HW1drVkgc9/M1D7fhJjgHldtX3WLsWBxo9+OYjIyCZ6Z/05MuSyamft5ZB/tAmivo2BvqvTHvNNNe13+2Hj72RpV7K29LRp01SQkaQwXbN3165dVTCU7f3339c/fujQofj333/VetCZCdQSWENCQtRz5DdXTJw48ZF+ZfkdNqyRyz4XLlyoArXUjiV4yYmFNHU/jqxdLUtB/v777yroiW+//VbVWKdMmaJOFoTUXuV2CZqVKlVCu3btsGnTpmwFanmenFjI8pOyzKSQ/UvNWE4W6tatq2rcI0eOVPsSsj62jtwnx1paKoS0JhibWVfZ5D9KzmjkP0gWD5frU6dOxcyZM5GXSVCe1KUaHO2sVbBevP9Bf5OjK9B2mvYLXvcNUxeTiMyQBI+GDRvi119/VdelhimJZNLsravgfP755yqQFC5cWAVMCboSYDJDfmslgOmCtJAa78MWLVqERo0aqUAs+5DAndl9GO4rICBAH6SFvKbUek+fPq2/rWrVqipI60jtWmrf2aF7f7ogLaR5X5LP5D7x7rvvqpp9ixYtMHnyZJw/f17/2GHDhmHChAmqnJ988km2kvcsqka9a9cu1UQhZ0+6szbpawkODkZeJ83d775QARPXhGDC6pN4rlIR1SwO/65Alc7pm71lPes83IJAlKd8dD17Td86lTpoX0Oavg2NOIacIkFZasrfffedqk1Ls3azZs3UfVLb/t///qf6nCVYSxCUpmtprs0pu3fvVs3D0g8tTddSi5fa9FdffQVjsHvQ7GxY2ZFgbizSkvvaa6+pboO1a9eqgCzvr3PnziqAy3uW+9avX49Jkyap9y3/H/myRi1njdJMcebMGX0H/44dO56Y2p+UlISYmBj9FhsbC3PVr1EZVCvhhpjE+xi/8kTaHYZBetuXwJqRHLpFlFukzzirm65/Wshluc2wf/pJr5sNkvxkbW2tmo6l2Vaaw3XdgTt37lQVnNdff13VVqVpVvcbmhmVK1fG1atX1TAqnT179jxSifL19VX95JJpLk3DkmSV7u3a26va/dP2Jb/r0letI+WX91axYkUYQ+UH7082Helnvn37tqpZ60ii3DvvvKOCsfTZywmRjtTGBw4ciKVLl+K9997Dzz//DGMy60A9atQovPLKK6qpR86opHNfzgzlTO5x5OxG108jm+GBN8cVtiZ3raZW2FpzLBzrjoenf0D4ceC/CcC+n4F1oxmsiUiRpmZJfho9erQKqJK7oyNBU7K0JZhKU+5bb72VLqP5aaS5V4JU7969VRCVZnUJyIZkH9LMLbVMaRaeMWMGli1blu4x0gIq/cCSiHXr1i1ViXqY/JZLZrnsS5LPJFlMaqaS/Kbrn84uOUmQfRtucjzk/UlLg+z74MGDqoVWEvSkRUJOOu7evauS2SSxTE4+5MRB+q4lwAuJQdKVIO9Nni9l1t2XLwO1JD/Mnz9fnTXKAfntt99Uir78fRz54EqWom6TMyVzVtXbDW811SYjDF94CKuOGjS7efkDL87QXt47SzvdqDSDE1G+J83f0dHRqhnWsD9Z+opr1aqlbpdkM+lDluFNmSW1WQm6ErAk+Uyaer/44sGUxw+8+OKLqrYpAU2yr+WkQIZnGZKEK5mcRYY5yZCyjIaIydAuCXpRUVEqieull15CUFCQykt6VnFxcapyZ7hJkpq0PKxYsUIlqMkQNAnc0uogfe5C+sJliJsEbzlhkdYLacWVZn7dCYBkfktwlvcnj/n+++9hTFYajfn+8kvzgtSq5aDoSCe+ZIFLVmJmyMQA8jrSzOHj4wNzlJicgiHzD2JTiDY54p0WFTAsqFxaZvv+OcCqBxngDYcBL3zGPmuiZ/3eJSaqWlGZMmVUrY4oNz9jWYlNZl2jTkhIUGd3huRsx5hJBKZaYeunXnXwZuMy6vrXG89g+MLDKoArdfoC7R4kaeyaAWz6lDVrIqJ8wqyzvqWZQppcSpUqpdLzDx06hOnTp6vECUsj/dRj21dBuaIFMXb5caw8ch1XohLwU6/a2mzwum9qg/Oa94EdXwPWtkDzMaxZExFZOLOuUct4aemzGDx4sOoPkAH1khghYwQt1Sv1SuH3N+qpRTwOX72NTt/uxKmwGO2d9foDrSdrL2+bBmydYtKyEhFRPg/UMh2djAWUzDtJbJDsQumjlrR/S9awrCeWD2kEP09nXL+TiK6zdmHjyQdZm/UHAS0fJHZsmQRsnWbSshIRUT4O1PlZGU9nLBvcCI3KeSDhXgr6/7EfP207D5X71/BtbUKZ2DwB2G6cSQaIiMj0GKjNmJuTHeb2rYfXAkup7mmZxWzU38dw734q0Gg4EPSJ9oGbPgPCc27WI6L8xIwHvlAel5pDic9mnUxGgJ2NNb7o5I9yRQqqqUYX7b+KS5Hx+OH12nBv8i6gSQWciwBe2gniiShzZBIlGQJ58+ZNNc43Ly/0Q+Z38idTtspnS0YuPWt3rVmPo84JeWEcdWZtPh2BoQsOIS7pPnw9nPBL77oqSzyd+0mALRdlJ8rspBjyG2HhP4NkIjKhiywgklGgzkpsYo06D2lesSj+HtQQb/y2D5cjE9D5+52Y1aM2Gpf31D4g/hbwe0egVm8gcICpi0uUJ6bilOkwk5OTTV0UsjA2NjZqmc+caKlhoM5jKnq5qIzwgX8cwP7L0eg9JxjjX6yKnvV9gWNLgBvHgR3TgYBXtMtmEtFTf1ANl1AkMjcM1HmQZ0EHzO8fiNF/H8PSQ9cwbvlxnI+Iw9i2/WGbHA9U7sggTURkIZj1nUc52Nrgq+4BGNlKuxTc3F2X0O/3A4ipOwzwLJf2wNjMr5pDRETmh4E6D5O+jyHNy2FWj1pwtLPGtjM30fX7XbgSmaB9wNmNwP8CgEPzTV1UIiLKJgZqC9CmWnEsGdgQxVwdcDYiDp2+34ngi1HAhc3A/bvAiiHAH52Bg78DCVGmLi4REWUBA7WF8C/hhhVDGqNaCTdExd9Dj9l7sMRjIBA4UEb1Aef/A1YOBb4sD8zvBhxeACTeMXWxiYjoKRioLYiXmyP+eqsB2vh7ITlFg/eXHMUUq75IHXIAeH4sUMwfSL0PnF0PLB8ETCsH/PkqcPQvICnW1MUnIqIMcMITC5SaqsH0DWfw7eZz6nrLKsVU4pmLox1w8wxwYhlwYilwMyTtSbaOQPkXgHbTgYJFTVd4IqJ8IDQLE56wRm2BrK2t8H6rivj65QDY21hj/ckbaP3Ndmw/exMoUgF47kNgyF5g0G6g6UigcFngfiJwaQdQwD3thW6cBJLvmvKtEBHlexxHbcE61/RBqcLOeGfRYVyJSkDPX4Lxar1S+KhtJW3tulgV7dZ8jHZRj+hLgI2d9skypeKC7trks97/AD61Tf12iIjyJdaoLVxtX3esHd4EvRv4qut/Bl9Jq13ryBR3xasDVV5Muy3metplCeY6p1YBZ/4F7t/LlfITEeV37KPOR3afj8QHfx/B1Shtc3a62nVGpFYdfREo7Jd2/btA4NZpwLEQULk9UDIQsJaGGSvAyvrBJpcNrpeoA7iV0L5GTBgQfhRw8gB86qTt6/JubaKb7vnymh7lAKfCRj8uRES5jYtyUIYalPXAuuFNMXVdCH7bfVnVrmWSlMldq6FJ+SKPPkECpi5Ii5R7gN9zQOJtIO4GcGiednuabnMBt87ay1d2AUv6AaWbAH1WpT1m4WvA3QzGeLuXAUrUArxrASVqa2v+9s78HyaifIN91PmMs4MtPu3oj9b+xfW160f6rh9Hls9sOxVoPQm4vAs4uRy4fUVb05Z1sWWD7rLBX6cHq3sJqYl719TWlg15VtCeAOheR5brvHNVW6OX7fjf2sdJjbtoFe1r1BugDdxERBaMTd/5WHzSfX3tWpQoVABTulZPWzbT1O5GA9cPA9cOANcPaf/GhqXd33sVUKaJ9vL5zcCZddohZuVamKzIRJSHJCcC9+IebPEPtsddjgfcfID6g3Jk12z6pmzXrl//ZW/mate5QYaKlW2u3QyT3K4dBK4fBLxrpN0uk7js/UFbG9cF6nsJwPYv05rNXYvn/nsgIuNIuQ8kRAIJt4D4Ww/+Prh+9zbg5Q/U6qV9rCS//tJCG2wHbAEcXLS3r3kvc913OpKTk0OBOivY9E36vusp60Lwu0HftVnVrnVcvbWbJLIZkpq0NLMb1qbDjgDbv0q77lJcG7SLVQUc3QCHgoB9Qe2XVvq9dZelX9yaAyKITBJ8I05qA7DhCXrwz8CFLdrb429qA7N0lT1J5Q5pgVqGncoQVDmRl2CtC9TynRd2Tg9+Ax78DugvP3RdfhtMgE3flM6u87fw4d9H9ZnhrwVK7boyCjrkwXO68OPaWrY0m8uXX/WhZ8K4W2njyWV+9LMbtFOw1nxde5vM7rZ1SlqgVwFed9n5wZfeSftX9wMgfwsW4wkAWQY5KZZph2WiJMOZDOU7F3MNSE7QTpYkQVH+qu3BbcnxafdJ4JUEVfl+icQYYHJJ7eWPwrTfI7F8MHA4o1UArbQtb86e2lwYZw/tX7lNTsirvZT20HObALsC2tY1ybfR1bStbbRbLmPTN2Vbw7Ke6WrXC/ZewdbTZlq7fhpp+ur4rfay/CiEHdX2c0ee0/Y9Jen6pgwupySnBWkRd1PbLy5Dx3RiQoHjS7JenpEXtD8k4t8xwPGlQOMRQOBb2tuiLwP/fpRBoJe/D87oDU8OdNfdSqYvM5mG/OjrmmJVzU/+RqVdl8vqc6TRPr7G60DF1trLESHApk8BFy+g/ddpr7lmpHYiIl1w1F5If1l/34PL1bqlnVTevqqd118+L68tTHvddaO1XUgPP/+RfWi03wkJsv5d0wJqXATwVQVtoPwkWjtCRMgJ7KmVWTtuzgaBXmq68nmWv/J91AXqai9pE0j1AdkzLSDbZLISUS7o0dts7ZEXmH016dq1a/jwww+xdu1aJCQkoFy5cpgzZw7q1DEYg0s53nf9meq79tLXrqXvOk/XriWo+TbQblnR7iug+WjA9cE4cCFTrraamHGgVzUIw9pEgravXGoRuh8dIT/isde1NRLD20IMhqxl1tCDgEdZ7eWtU4H9c4C6bwBN39feJgFi7Qfpm/cNL9vYA5oUIDVF2+qg/qYAFdumjWMPPQBc3aud/EZqQELe164ZaY/XP9fgNWQ8vJxE2Dho9yOXq3YC3EtrXyPqgraLwtUHKFk37T1JEFHPs0/bpBZkeJtuzL0xSJCS1eUkwMox0E2tKwH18DxtkJCTLJ1vqgO3tUmZmebbKH3i5Ok12s+WIRldceN41l5X5i3QUVMDb9d29Ri6cQK4uidrr2uYyCk1U/0+kgA7R+1l+RxKQFUnmQUebAYnnYa3yfdB5lPQfRaE/H++k8H7Lfu8dsunzPoXNzo6Go0aNULz5s1VoC5SpAjOnj0Ld3eD+ajJaCyqdp1dMlGLbrIWHXdfoMGQrL2OvqbyQItPtEkpUoPS78tHuyiKvpnQIMjLX30WqsGJgfzV9bcJ6b97+ARAAvWxxciygTvTAvX5TcDmL4DafdICtexjy6Ssv27xgLQfZ+l3XPUOUKk98IpB0+bsFtpAnxm6iXW6/Az4d0mbQW/ZW9rkn55L0x4rE/ZI8H1kgh6Dv3L85TG6VpQXvwVq9UxrTdk1U7sSnWGglhMHVRYb7TGTQC5BSC6r2p8HUKCw9kRDd3JRsn7a82W+gg7/S/9/KZ4bpU2M0p+QPJhMSP6qqxlcLlop7fny+XppzqMtLvK6dd/M+PkP70ueK4HV8LMq5RxzQ3vyZHiy1GJ8Jv7DyKIC9ZQpU9TqIlKD1ilTxjSd+fmVYe36gyVHERqtrV33CCyF0Xm1dm0KD9f8dElxhlyKaWvCz6LJe0CN1wBngwlspDbY8osHgT42fe1f+hllIhsJMLq+Ot1lw4llilbWNn1KMp7himt1+qU9Xhf4DF9Datby+rJJzUuaUQ3ftzR7+jbWvr5Oaqr2MYbPSUlK3/1gSD+G30BqsvY9Gp6wCF12cGZJq4PsW0fG/zd4O30tUPRa/qArwi17eQjyfy8nQRklRD0LCai6kxdDvg2f/fOsq0VT/k4mq1KlClq1aqU63bdu3YoSJUpg8ODB6N+/v1E67Onp464nrw3BH3vSxl2Pa18ZTSsUgZM9AzYZmQRwXdCX4P3wBDvSvKvrXpCTkfgI7cmE4YmBJAJKEE83KY/udR5cl1qirkbMYERGkpXYZNaB2tFRe8b27rvvolu3bti3bx+GDx+OH374Ab17987wOUlJSWoz7OOWgM9AnbOZ4bratbCzsULNku5oWM4Djct5IqBkIdjZcHgTEZHFB2p7e3uVNLZr1y79bcOGDVMBe/fu3Rk+Z/z48fj0008fuZ2BOudr1zM2ncWqo2G4djv9mtXO9jaoV6YwGpXzVP3clbxc1BrZRERkYYHa19cXL7zwAmbPnq2/bdasWZgwYYKqKWeENercJR8fWet657lI7Dx/S63QFRWffglMD2d7NamKBO5GZT1RysMg+5mIKB8KzUKgNuuORcn4Pn36dLrbzpw5owL44zg4OKhNJyYmxqhlzO+srKzg6+GsNhm+lZqqwanwGOx6ELiDL0YhMv6eqnnLJnzcC6iA3ai81Lg94Fkw7f+LiIhyIFDLGYD8QOvOAoKDg7FgwQLVFzxgwADklHfeeQcNGzbExIkT0b17d7Wfn376SW1knqSJu6q3m9r6N/XDvfupOHz1Nnaeu6X6tg9dua36thftv6o2IU3j0kTeqJwHAv08mElORPSsTd9NmjRRAblnz54IDw9HxYoVUbVqVTXGeejQofj444+RU1atWoXRo0er15ahWZJYxqzvvN23HXwpCrvO3cKOc5E4FZa+xcPG2go1ShZCo7IeqO/ngZql3FHAPven9yMiytN91DLhyJ49e1SAnjFjBhYtWoSdO3di/fr1GDhwIC5cuABzweFZ5i0yLgm7L0SqPm6pcV+OTEh3v2SUV/cphMAyhVWCWm1fd9Ov6kVEZO591MnJyfp+4I0bN+LFF19UlytVqoSwMINp5oiewqOgA9pX91abuBqVoAL2rvOR2HshCuExiThwOVpt3285D0kel2Z1XeCuW7ow3J3zxny9RETZka1ALc3cMpa5Xbt22LBhAz7//HN1+/Xr1+Hh8WDRAaJsKFnYCS8XLoWX65ZSGeUyz/jei5HYezFKJaZJhvmxa3fUNnvHRX0ftwTtwDIeqFvGHUVdOGMSEeXzQC1Te3bu3BnTpk1TE48EBASo21euXIl69erldBkpn5KERRnKJVu3Otql78Lu3FUBWwL33guROH8zHiHhsWqT+ciFn6czAv20Ne56ZTzUDGpERHlVtsdRp6SkqKFPhgtkXLp0CU5OTiha1GDZMhNjH7VluxWXhH26wH0xCiHhMY+sfyHDwbQ1bm2t29fDSZ0EEBFZbB/13bt3VbOkLkhfvnwZy5YtQ+XKldXc3ES5RcZgt6lWXG3iTkIy9l2KUpnlUuM+fj1GDQcLjb6GpQe1k+SU9nDC9z1qo4q3K/+jiMjsZStQd+zYEV26dFEZ3rdv30ZgYCDs7Oxw69YtTJ8+HYMGDcr5khJlgpuTHVpUKaY2EZd0HwcvR6t+bmkyP3L1Di5FJqDXr3vx11sN4FekII8rEZm1bK2ccPDgQTWWWixZsgTFihVTterff/9dDdciMheyDKes7jWyVSUsHtgQwWOCUKW4K27F3cPrs/c+Mk85EZFFBOqEhAS4uGgXOJex01K7tra2Rv369VXAJjJXhZzs8fsb9eBXxBnX7ySqYH0z1mC9YSIiSwjU5cqVw/Lly1Un+L///ouWLVuq2yMiIuDqyn4/Mv9+7XlvBKps8Iu34tHzl724nZB+IREiojwdqGWK0Pfffx+lS5dWw7EaNGigr13XrFkzp8tIlOO8CxXA/DcDUcTFQQ3t6jNnn+rPJiKyiED90ksv4cqVK9i/f7+qUesEBQXh66+/zsnyERlNaU9nVbMu5GSnFg7p/9t+JCan8IgTUd4P1MLLy0vVnmU2MhkPJqR2LdOIEuUVFb1c8FvfenC2t1Fzjg+ZfxDJKammLhYR0bMF6tTUVHz22Wdwc3NTa0PLVqhQITWVqNxHlJcElCyEX/rUhYOtNTaFRODdv44gJTVb8wAREZlHoB4zZgy+/fZbTJ48GYcOHVKbrBk9c+ZMjBs3LudLSWRksqTmD6/Xhq21Ff45ch1jlx9Tk/oQEeXJKUS9vb3Vohy6VbN0VqxYgcGDB+PaNe0MUOaAU4hSVqw6eh3D/jwEqVD3b1IGH7WtzOlGiciksSlbNeqoqKgM+6LlNrmPKK+S5TYnd6muLv+8/SJm/nfO1EUionwuW4FaVsuSpu+HyW3Vq2t/5Ijyqu51S2Jc+yrq8vQNZ/Drg+U0iYjyzFzfU6dOVWtRb9y4UT+Gevfu3aoKv2bNmpwuI1Gue6NxGcQl3sfXG8/gs1Un1VSkEsCJiPJEjbpZs2Y4c+aMWpNaFuWQTaYRPXHiBP7444+cLyWRCQwLKqf6qcWopUex+mgY/x+IKO+sR52RI0eOoFatWmqtanPBZDJ6FvL1+GjZMfwZfBV2Nlb4qWcdNK9kPuutE1HeZPRkMqL8wsrKChM6VUOHAG8kp2gwcN4B7LkQaepiEVE+wkBN9BQ21laY3j0AQZWKIul+Kt78bT+OXL3N40ZEuYKBmigT7Gys8V2PWmjg56EW7+g9Jxinw2N57IjIvLK+JWHsSSSpjMhSOdrZ4OfeddQa1rKIx+u/7MXitxqoxT2IiMyiRi1zez9pkzm/e/XqZbTCEpmaDNOa27cuKnm54GZsEnrM3ouwO3dNXSwismA5mvVtbDK3+OjRozF8+HB88803mXoOs77JGCJiE9H9h924FJkAvyLO+OutBvAs6MCDTUT5N+t73759+PHHHznzGZmFoi6OmPdmILzdHHHhZjx6/RKMO3eTTV0sIrJAeSJQx8XFoUePHvj555/h7u5u6uIQKT7uTipYexa0x8mwGPSbuw8J9+7z6BBR/gvUQ4YMUVOWtmjR4qmPTUpKQkxMjH6LjWVmLhmPX5GC+L1fIFwdbXHgcjTe+uMAklO4JjsR5aNAvXDhQhw8eBCTJk3K1OPlcYYJblWqaBdXIDKWKt6umNuvHpzsbbD97C2MWca1rIkonwRq6WSXxLH58+fD0dExU8+RZLM7d+7ot5MnTxq9nES1Srnj29dqwtoK+Gt/KL7bzOUxiSgfBOoDBw4gIiJCzR9ua2urtq1bt2LGjBnqckZzijs4OMDV1VW/ubi4mKTslP88X6kYPn2xqrr85fozWH7oGsxZaqoGMzadxTuLDuNOAhPhiMxVtpa5zC1BQUE4duxYutv69u2LSpUq4cMPP4SNjY3JykaUkZ4NSuNq9F38tO0CPlhyFF5ujqjv52F2B0tGZX6y8gT+2HNZXb9wKx7z3qgHF0c7UxeNiPJSjVpqw/7+/uk2Z2dneHh4qMtE5mhU60po4++FeympKrnsXEQczC1If/rPSRWkrawAFwdbNXc5s9aJzJNZB2qivMja2gpfv1wDNUsVUmOr+8wJVrOYmUuQ/nzVKczddUkF6aldq+PPAfXh4miLfZei1YIjicnms0wtEeXBQL1ly5ZMz0pGZMp5wWf3qoNShZ0QGn0Xb/6+H3fvpZg8SE9aG4Jfd15U1yd3qYZudUrCv4QbfutXD872Nth1PlIt5Zl0n8GayFzkuUBNlFd4FHRQ84IXcrJTTcsjFh1CSqrGZEF6yrrTqu9cTOxcDS/XLZUua/3XPnXhaGeNLadvYuiCQxwPTmQmGKiJjDwhyk8968Dexhr/nriBiWtOmSRIf7X+DH7Yel5d/7xjVbwWmBakdQL9PDC7V13Y21pj/ckbKhvcVCcWRJSGgZrIyOqVKYwvuweoy7/suIi5D5qec8s3G8/i2wfjusd3qKIy0x+ncXlP/PB6LdjZWGHV0TCMXHJEDeMiItNhoCbKBS8GeOOD1hXV5c9WncSGkzdy5bjLOOn/bTqrLo9tVxl9GpXJ1Hjwma/WhI21FZYevIaxK46rWjkRmQYDNVEuGdSsLF6tVxJSQR325yEcDb1t1P3J7GjTN5xRlz9qWwlvNvHL9HNb+xfH9O4BKjN8wd4r6uSCwZrINBioiXKJlZUVPuvoj6YViuBucgr6zd2P0OgEo+xL+qOn/XtaXf6wdSUMaFo2y6/RsUYJNXxLzNl5SSWjMVgT5T4GaqJcZGdjje9eq4lKXi64FZeEvnP25fg61j9vu4DJa0PU5fdbVsCg57IepHVk+NaETv764K9rRiei3MNATZTLZJrOOX3ropirA85GxGHgHwdw737OLI0pyWpfPMgsf6dFBbz9fPlnfs3X6/tiXPsq+sS0WVu02eNElDsYqIlMoLhbATVuWSYZ2X0hEqOWHn3mZmXJJv98lXa1uGHPl8PwFs8epHXeaFwGI1tpk+GmrAvBrztyN3OdKD9joCYykarebviuRy19dvWzNCv/sfsSxv+jDdJDmpfFOy9UQE4b0rycOgEQklwmSWZEZHwM1EQm9FzFovi8o7++WXnJgdAsv4YEzHErTqjLbzXzw/stK6rENWOQE4C3mmqzx8csP4a/s1He7JI5yGXp0B6z96DGZ+vx1h/78c+R60i4dz/XykBkCma9zCVRfiCzhF2NTlB9v6P+PgpvN0c0LOeZqecu2ncFHy3TLgXbv0kZtXKXsYK0kNce1aYSku6nqoU9ZEIUmcmsQ4C3UfYn3QFHQu/gr/1XVVCOTUwLyjLTm2wF7GwQVLko2lf3xnMVi6h51oksCQM1kRkY2bIirkYlqNnA3pp3AEsHNUT5Yi5PfM7i/Vcxaqk2SPdtVBofta1s1CCtI/v4uH0VVcNduO8qRiw6rIJ1q6peObYPWW1Mas8SoCXhTsfHvQC61S6J+n6Fse3sTXW8Lkdqj5tsBR1s0bJKMbQPKI7G5YqochHldVYaCx8YGRoaipIlS+Lq1avw8fExdXGIHksC3+uz92L/5WiUKFQAy4Y0RFEXxwwfu/RgKN5bfATy7e3dwBfjX6yaK0HakMwD/v7iI1h26JqacvSnXnXQvGLRbL9eckqqWhBEgvPmkAjcfzB1qYOtNdpWK45udXxQv4yHWkZUR36+jl27ow3UR67j+p1E/X1uBezQqmoxVdtv4OcBWxsGbcqbsYmBmsiMRMXfQ9dZu3DxVjyq+7hh4YD6cLJP3/C14vA1tWCGxLHX65dSfdy5HaR17qekYvjCw1h9LEwFVMlkb5TJZnudszdisfhAqDr5uBV3T397jZKF0L1OSVU7dnW0e+rryJzkh65G458jYVhzLAwRBmuAezjbo7W/lwradUsXVgl8RKbEQJ3Ng0FkDi7dikfn73ciOiEZLSoXw489a+sDi/TTDl94SAXpV+uVwhed/NPVME1BasKD5h3ExlPa/mJZ21oWInmSmMRk9V4W7w/F4atpU6l6FnRAl1ol0K22z1Ob/p9W2w++GIVVR69j7fFwdQKkU9TFQdXQJWjXKlXIZCc5lL+FskadvYNBZC4OXI7Cqz/vVROh9GlYWjVtrz4ahmELtWtav1ynJCZ1qWbyIK2TdD8F/X8/gG1nbqp+4nlvBqoa8cM13j0XIlXTtgRPSUgTttZWeL5SUTULmiSDyextOV3r33U+UgXtdcfDEWOQkCZdDO2qF0f76sVRrYQbgzblGgbqbB4MInMigXnIgoPqcueaJbDyyHUVpF+q7aPm4DaXIK1z914K+s4Nxp4LUXB1tMWC/vXhX8JNJcn9fTBUDT0Ljb6rf3z5ogVV03anmiVQxMUhV8ooJz7bHyShyQpmcUlpQdvXw0kF7C61fFC2SMFcKQ/lX6GsUWfvYBCZmx+3nsekB/N2iy41S2BatwCz7WONT7qPXr8G48DlaLg72aFycVdVm9VxcbDFizW8Ve05wMe0NVhJ3ttyOgL/HA3DplM3kJisreHLsR3Q1A/Dg8pzqBcZDQN1Ng8GkbmRrObxK0/gt92X0amGN77qXsNsg7Rh/7Nkrx8NvaO/rVE5D1V7liFc5jjOWSZN2XQqQtX6t565qW4r4+msuhfq+3mYunhkgRios3kwiMxV2J278HJ1zDN9qLcT7mHqv6dV4lbXWj4oWdgJecX6E+EYt+I4bsQk6SekkUleMpN5TpRZDNTZPBhEREKWHpWlQv8M1s5nLiudyTC4ljk4qQvlb6FZiE2cAYCI6CEyWYo0e8s4dmkCl9r1gD8OYMj8g2rWNKLcxEBNRPQY0j+9dngTDHqurMoNkIldWkzfqoaYWfikjmRGzDpQT5o0CXXr1oWLiwuKFi2KTp064fTp06YuFhHlI5L89mHrSlgxpBH8S7iqZvEPlhxFz1+CcSUywdTFo3zArAP11q1bMWTIEOzZswcbNmxAcnIyWrZsifj4eFMXjYjyGRkTvnxwI5VYJtOl7jh3Cy2/2YrZ2y+o8e1ExpKn5vq+efOmqllLAG/atGmmnsNkMiLKaTIX++ilR9XkLkLGhE/uWl2NGyfK18lkd+5ox2UWLvzkeYSJiIxJEsz+7F8fk7tUg4ujrVozu8PMHfjy39NqIhWinJRnAnVqaipGjBiBRo0awd/f/7GPS0pKQkxMjH6LjY3N1XISUf4gY9pfqVcKG99tppbTlGU5v918Dm1nbFcLghDlu0AtfdXHjx/HwoULn5qA5ubmpt+qVKmSa2UkovynmKsjfuxZB7N61FJzll+4GY/uP+7G2OXHEJuYbOrikQXIE33Ub7/9NlasWIFt27ahTJkyT3ys1Khl07l27ZoK1pzwhIiM7U5CMiauOYVF+6+q68XdHDGhkz+CKhfjwSfL7KOWcwgJ0suWLcN///331CAtHBwc4Orqqt9kaBcRUW5wc7LDlJeqY8GbgShV2AlhdxLxxm/7MfTPQ7gVx4lSKHuszb25e968eViwYIEKuOHh4Wq7ezdtqTwiInPTsJwn/h3RVK3CJWuo/HPkupooZTEnSiFLa/p+3AIEc+bMQZ8+fTL1GhyeRUSmdCz0Dj74+yhOhcWo6/X9CmNCp2ooV5RrXudnoZbU9J3RltkgTURkatV83LDy7UZqdjNHO2s19rrt/7Zj+oYzHMpFmWLWgZqIyBLY2Vir+cI3vNMMz1UsgnspqZix6Sza/G87dp27ZerikZljoCYiyiWyLvecPnXx3WvaoVwyw9lrs/fi3UWHEclkM3oMBmoiolzOvWlXvTg2vdcMPev7QlJxlh66hqDpW7Fo3xWkmsG84VejEjBp7SnUn7gJ7WZsx6ZTN7hamAmZdTJZTmAyGRGZs0NXovHRsuP6ZLN6pQvji87+KF8sd4eWygnC1jM38ceey9h8OgIPR4Z6ZQpjdJtKqFnKPVfLZamyEpsYqImITOx+Sirm7LykEszuJqfAzsYKbzUti7efL6eW2TSm6Ph7an3teXsv42pU2tDXphWK4LV6JXH46h3M2XkRSfdT1e3tqhXHyFYVUdrT2ajlsnShDNTZOxhERKYUGp2AT1acwKaQCHXd18NJzWzWpHyRHN/Xkau38fvuy/jn6HXcexCEXR1t0b1OSfSo76sWHtG5fvuuOon4+2CoqmnbWlvhtcBSGBZUHp4FHXK8bPlBKAN19g4GEZGpSW/kvyfCMX7lSYTHJKrbOtbwxth2VVQC2rOQlb1WHrmOeXsu42iodjVC4V/CFb3ql0aHAG8UsH98DT4kPAZT1oZg8+mb6rqzvQ3ealYWbzYpAyd722cqW34TykCdvYNBRGQuZEGPr9afwe+7L0Hyy6S2O6pNZbxStySsZbqzLLgcGa+C81/7Q3HnrnahEHsba7SvXhw9G/iiRslCj51gKiO7zt/C5LUh+mAvJxAjWpTHy3VKwtaGOcqZwUCdzYNBRGRujobexkfLjuH4NW2yWW1fd0zsXA0VvZ6cbJaSqsGW0xGqeVuSxHR83AugR6AvutfxgcczNFtL8tnqY2GY9u9pXIlKULeVLeKMD1pXQssqxbIU+POjUNaos3cwiIjMNdlMAu5X608j/l6K6iPu39QPw54v/0hTtYzHlprz/L2XERqtTQ6TmNmsQhE1HOy5ikVhk8Ua+ZNI/7bsa+Z/5xAVf0/dVsfXHaPbVkJt38I5th9Lw0CdzYNBRGTOJKlr/MoTWH/yhrpesnABfNbRH89VKIJDV29j3u7LWHU0TM18Jgo52WmTwwJLwdfDuFnaMYnJ+HHrefyy4yISk7X7b1W1mKphly3Cec0fxkCdzYNBRJQXrFfJZidw/U6ivjlbV3sW1X3cVO1ZksOMPbzrYeF3EvHNxjNqyJf0rUvtXfrVh7coj6IujrlaFnPGQJ3Ng0FElFfEJ93H1xvO4NedF1VAtLe1Rofq3ujVwBcBJQuZung4eyMWU9aFYOMp7VAzJ3sbvNnETy39WdCBGeKh7KNOw0BNRJZMZjQ7fPU2Wlf1gruzPczN3guRmLQ2RJVReBa0x/Cg8nilXim1WEl+FcpAnb2DQURExhkbvvZ4OKauC8GlyAT9ZC4N/DxUs72Pu5P6W8K9gGoez8lkN0uITWx/ICIio5KhWm2rFccLVYphYfAVfLPxLC5HJqjtYTJ9qnchCd4FUKJQWhCXvxLIvVzzRyA3xEBNRES5Qpq6ezYojc61fLDhZLgK1JIEdy36LkJvJ+D67UQkp2geG8SFDE0rXsgRPoW0gTtdjbxQARR3c7S4SVcYqImIKFdJMlnnmj4Zjhe/EZuE0KgEXLt9VwXx0OgHwfz2XTU8TQK5LB5iuICIIaltS8Cu5OWCysVdUbm49m9Jd6csz+hmLhioiYjILEhNWIKsbI+bbS0iNlEfwFVNXL9pg7sEcpkpTTbdeHPdvOQym5sE7UrFXVGluAsqernmiQx08y8hERERtLXl4m7SvF0AdUsXznBa04jYJFy4GYdT4bEqI14WEjlzI07N6Hbwym21GSpV2Mmg9q2tgZtb7ZuBmoiILIK1tRW83BzV1rCcZ7om9Yu34nFSBW5tAJftRkzSY2vfUus2bD43Ze2bgZqIiCy+Sb18MRe1dTS4XeYmD5GgnUHt+8DlaLU9XPuWRVG+frlG7pY/V/dGRERkJgo726ua99Nq3yFhsWptcKl5y3NyGwM1ERFRZmrf4THQaJDrGKiJiIgyU/sum1bzzk15YlT4d999h9KlS8PR0RGBgYEIDg42dZGIiIhyhdkH6kWLFuHdd9/FJ598goMHDyIgIACtWrVCRIR2RRYiIiJLZvaBevr06ejfvz/69u2LKlWq4IcffoCTkxN+/fVXUxeNiIgofwfqe/fu4cCBA2jRooX+Nmtra3V99+7dGT4nKSkJMTEx+i02NjYXS0xERJSPAvWtW7eQkpKCYsWKpbtdroeHh2f4nEmTJsHNzU2/SS2ciIgor7K4rO/Ro0erPm0dWevT398fYWFhJi0XERGRji4mpaamIk8Hak9PT9jY2ODGjbSp3YRc9/LyyvA5Dg4OatNJSNAulVavXj0jl5aIiChrJJ6VKlUq7wZqe3t71K5dG5s2bUKnTp30Zx9y/e23387Ua9SsWVMN55LmcunffhbS3y1N6SdPnoSLi8szvVZ+wWPGY8bPmXnid9O0x0ximQRpiVFPY6XRmGKelawNz+rduzd+/PFHVSv+5ptv8NdffyEkJOSRvmtjk+Q06fe+c+cOXF1dc3XfeRWPGY8ZP2fmid/NvHPMzLpGLV5++WXcvHkTH3/8sUogq1GjBtatW5frQZqIiMgUzD5QC2nmzmxTNxERkSUx6+FZ5kaS1GSGNMNkNeIx4+fM9Pjd5DGz5M+Z2fdRExER5WesURMREZkxBmoiIiIzxkBNRERkxhios4DrYmeezLlet25dNSlA0aJF1YQ1p0+fzvonNJ+aPHkyrKysMGLECFMXxaxdu3YNr7/+Ojw8PFCgQAFUq1YN+/fvN3WxzJasnTBu3DiUKVNGHa+yZcvi888/B1OV0tu2bRs6dOgAb29v9T1cvnx5uvvleMmQ4eLFi6vjKAtFnT17FsbCQJ1JXBc7a7Zu3YohQ4Zgz5492LBhA5KTk9GyZUvEx8dn/VOaz+zbt09N8FO9enVTF8WsRUdHo1GjRrCzs8PatWvVbFFfffUV3N3dTV00szVlyhTMmjUL3377LU6dOqWuT506FTNnzjR10cxKfHw8AgICVOUsI3LMZsyYoZZd3rt3L5ydndGqVSskJiYap0CS9U1PV69ePc2QIUP011NSUjTe3t6aSZMm8fBlQkREhIwu0GzdupXH6wliY2M15cuX12zYsEHTrFkzzfDhw3m8HuPDDz/UNG7cmMcnC9q1a6fp169futu6dOmi6dGjB4/jY8jv1rJly/TXU1NTNV5eXppp06bpb7t9+7bGwcFB8+eff2qMgTVqI62LTenJlHuicOHCPDRPIK0Q7dq1S/dZo4ytXLkSderUQbdu3VT3isyZ/PPPP/NwPUHDhg3VWglnzpxR148cOYIdO3agTZs2PG6ZdPHiRTVLpuF3VKYVDQwMNFo8yBMzk5nzutgy5zg9ffJ56WuVZkpZcpQytnDhQhw8eFA1fdPTXbhwQTXjyrK2H330kTpuw4YNU4v5yPoA9KhRo0ap+aorVaqkViaU37UvvvgCPXr04OHKJAnSIqN4oLsvpzFQU67UEo8fP67O3Cljsm768OHDVX++o6MjD1MmTwClRj1x4kR1XWrU8jmTfkMG6ozJgkbz58/HggULULVqVRw+fFidREvSFI+Z+WLTt5HWxSYtmaN91apV2Lx5M3x8fHhYHkO6ViIiIlCrVi3Y2tqqTRLyJGFFLkvNh9KTjFtZctBQ5cqVceXKFR6qxxg5cqSqVb/yyisqQ75nz55455131CgNyhzdb35uxgMG6iyui62jWxe7QYMGRvmPyeskB0OC9LJly/Dff/+p4SD0eEFBQTh27Jiq4eg2qS1Kk6RclhNFSk+6Uh4e8id9r76+vjxUj5GQkKDyawzJZ0t+zyhz5LdMArJhPJDuBMn+NlY8YNN3Jkk/mDQNyY+nbl1sSeHv27evUf5jLKG5W5rXVqxYocZS6/puJOlCxh1SenKMHu6/lyEfMj6Y/foZk5qgJEdJ03f37t0RHByMn376SW2UMRkbLH3SpUqVUk3fhw4dwvTp09GvXz8eMgNxcXE4d+5cugQyOWGWZFg5dtJdMGHCBJQvX14FbhmbLt0HMl+EURgll9xCzZw5U1OqVCmNvb29Gq61Z88eUxfJbMlHK6Ntzpw5pi5ansHhWU/3zz//aPz9/dXQmEqVKml++umnXPifybtiYmLUkD/5HXN0dNT4+flpxowZo0lKSjJ10czK5s2bM/z96t27t36I1rhx4zTFihVTn72goCDN6dOnjVYerp5FRERkxthHTUREZMYYqImIiMwYAzUREZEZY6AmIiIyYwzUREREZoyBmoiIyIwxUBMREZkxBmoiIiIzxkBNRDnOysoKy5cv55ElygEM1EQWpk+fPipQPry1bt3a1EUjomzgohxEFkiC8pw5c9Ld5uDgYLLyEFH2sUZNZIEkKMtSfIabu7u7uk9q17NmzUKbNm3USmZ+fn5YsmRJuufLkpvPP/+8ul9W8BowYIBaUcjQr7/+qlZgkn3J2tCyrKmhW7duoXPnznByclKrDK1cuVJ/X3R0tFrCs0iRImofcv/DJxZEpMVATZQPybJ8Xbt2xZEjR1TAfOWVV3Dq1Cl1nyzf2qpVKxXY9+3bh8WLF2Pjxo3pArEEelnKVAK4BHUJwuXKlUu3j08//VQtP3n06FG0bdtW7ScqKkq//5MnT2Lt2rVqv/J6np6euXwUiPIIo63LRUQmIUvx2djYaJydndNtX3zxhbpfvvYDBw5M95zAwEDNoEGD1GVZKtLd3V0TFxenv3/16tUaa2trTXh4uLru7e2tlkd8HNnH2LFj9dflteS2tWvXqusdOnTQ9O3bN4ffOZFlYh81kQVq3ry5qqUakkXvdRo0aJDuPrl++PBhdVlquAEBAXB2dtbf36hRI6SmpuL06dOq6fz69esICgp6YhmqV6+uvyyv5erqioiICHV90KBBqkZ/8OBBtGzZEp06dULDhg2f8V0TWSYGaiILJIHx4abonCJ9yplhZ2eX7roEeAn2QvrHL1++jDVr1mDDhg0q6EtT+pdffmmUMhPlZeyjJsqH9uzZ88j1ypUrq8vyV/qupa9aZ+fOnbC2tkbFihXh4uKC0qVLY9OmTc9UBkkk6927N+bNm4dvvvkGP/300zO9HpGlYo2ayAIlJSUhPDw83W22trb6hC1JEKtTpw4aN26M+fPnIzg4GL/88ou6T5K+PvnkExVEx48fj5s3b2Lo0KHo2bMnihUrph4jtw8cOBBFixZVtePY2FgVzOVxmfHxxx+jdu3aKmtcyrpq1Sr9iQIRpcdATWSB1q1bp4ZMGZLacEhIiD4je+HChRg8eLB63J9//okqVaqo+2Q41b///ovhw4ejbt266rr0J0+fPl3/WhLEExMT8fXXX+P9999XJwAvvfRSpstnb2+P0aNH49KlS6opvUmTJqo8RPQoK8koy+B2IrJQ0le8bNkylcBFROaPfdRERERmjIGaiIjIjLGPmiifYW8XUd7CGjUREZEZY6AmIiIyYwzUREREZoyBmoiIyIwxUBMREZkxBmoiIiIzxkBNRERkxhioiYiIzBgDNREREczX/wFLqBZJBCF0AgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, steps=len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59027a18",
   "metadata": {},
   "source": [
    "#### Decoding strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f507fd7",
   "metadata": {},
   "source": [
    "##### Temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c504a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b27b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "probas = torch.softmax(next_token_logits, dim=-1)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6927f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "31814cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 X closer\n",
      "0 X every\n",
      "0 X effort\n",
      "582 X forward\n",
      "2 X inches\n",
      "0 X moves\n",
      "0 X pizza\n",
      "343 X toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} X {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba7c57",
   "metadata": {},
   "source": [
    "##### Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d6eae867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c7f09c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, temp) for temp in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], width=bar_width, label=f\"Temperature = {T}\")\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9ea2f8",
   "metadata": {},
   "source": [
    "##### Top-k sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "373f2307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "tok_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, tok_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6146c08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New logits after top-k filtering: tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(\"New logits after top-k filtering:\", new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "56203825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k probabilities: tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=-1)\n",
    "print(\"Top-k probabilities:\", topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e31c43",
   "metadata": {},
   "source": [
    "#### Text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "69661494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=1.0, top_k=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        \n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            logits = torch.where(\n",
    "                condition=logits < top_logits[:, -1],\n",
    "                input=torch.tensor(float('-inf')).to(logits.device),\n",
    "                other=logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probas, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0853ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens = 15,\n",
    "    context_size = GPT_CONFIG_124M[\"context_length\"],\n",
    "    temperature = 1.4,\n",
    "    top_k = 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "481bdd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text with temperature and top-k sampling:\n",
      " Every effort moves youlit terrace.\n",
      "\n",
      "\n",
      "\n",
      "\" he said deprecating laugh\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated text with temperature and top-k sampling:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3817c276",
   "metadata": {},
   "source": [
    "#### Loading and saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71d93597",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e673f300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fb5c5",
   "metadata": {},
   "source": [
    "##### Save both model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d2907807",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }, \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f2612078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, weight_decay=0.01)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505279f",
   "metadata": {},
   "source": [
    "#### Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0660e180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x17d15ad50>)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "       \"LLMs-from-scratch/main/ch05/\"\n",
    "       \"01_main-chapter-code/gpt_download.py\")\n",
    "\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a886c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: models/124M/checkpoint\n",
      "File already exists and is up-to-date: models/124M/encoder.json\n",
      "File already exists and is up-to-date: models/124M/hparams.json\n",
      "File already exists and is up-to-date: models/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: models/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: models/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: models/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "057b8980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "57b9aeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor shape: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor shape:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1c46c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12, \"context_length\": 1024, \"qkv_bias\": True},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16, \"context_length\": 1024, \"qkv_bias\": True},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20, \"context_length\": 1024, \"qkv_bias\": True},\n",
    "    \"gpt2-xl (1.5B)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25,  \"context_length\": 1024, \"qkv_bias\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "400d2c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5a45ff5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'n_layers': 12,\n",
       " 'n_heads': 12,\n",
       " 'emb_dim': 768,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': True}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "51590a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3a1eb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {left.shape} vs {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a63fe588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"w\"], 3, axis=1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T\n",
    "        )\n",
    "\n",
    "        q_b, k_b, v_b = np.split(params[\"blocks\"][b][\"attn\"][\"c_attn\"][\"b\"], 3, axis=0)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        ) \n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.weight = assign(\n",
    "            gpt.trf_blocks[b].norm1.weight,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.bias = assign(\n",
    "            gpt.trf_blocks[b].norm1.bias,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm2.weight = assign(\n",
    "            gpt.trf_blocks[b].norm2.weight,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.bias = assign(\n",
    "            gpt.trf_blocks[b].norm2.bias,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "\n",
    "    gpt.final_norm.weight = assign(\n",
    "        gpt.final_norm.weight,\n",
    "        params[\"g\"]\n",
    "    )\n",
    "    gpt.final_norm.bias = assign(\n",
    "        gpt.final_norm.bias,\n",
    "        params[\"b\"]\n",
    "    )\n",
    "    gpt.out_head.weight = assign(\n",
    "        gpt.out_head.weight,\n",
    "        params[\"wte\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "285abad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fa03403c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text with GPT-2 weights:\n",
      " Every effort moves you toward finding an ideal new way to practice something!\n",
      "\n",
      "What makes us want to be on top of that?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model = gpt,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens = 25,\n",
    "    context_size = NEW_CONFIG[\"context_length\"],\n",
    "    top_k = 50,\n",
    "    temperature = 1.5\n",
    ")\n",
    "print(\"Generated text with GPT-2 weights:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b9f30f",
   "metadata": {},
   "source": [
    "#### Fine tuning for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca449eef",
   "metadata": {},
   "source": [
    "##### preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "29a65467",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "70c2187c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "    \n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\" Primary url failed with error: {e}. Trying backup URL.\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "693b6cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will  b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will  b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"label\", \"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "6edfae3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "fa076ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset label counts:\n",
      " label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"label\"]==\"spam\"].shape[0]\n",
    "\n",
    "    ham_subset = df[df[\"label\"] ==\"ham\"].sample(n=num_spam, random_state=123)\n",
    "\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"label\"]==\"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(\"Balanced dataset label counts:\\n\", balanced_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "846e9d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict = {\"ham\": 0, \"spam\": 1}\n",
    "balanced_df[\"label\"] = balanced_df[\"label\"].map(map_dict)\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e2b4a98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset label counts:\n",
      " label\n",
      "0    747\n",
      "1    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Balanced dataset label counts:\\n\", balanced_df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "83c318eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac=0.7, validation_frac=0.2):\n",
    "\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    val_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df.iloc[:train_end]\n",
    "    validation_df = df.iloc[train_end:val_end]\n",
    "    test_df = df.iloc[val_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "f3432dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = random_split(balanced_df, train_frac=0.7, validation_frac=0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "val_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8b115745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Dude how do you like the buff wind.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Tessy..pls do me a favor. Pls convey my birthd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Reminder: You have not downloaded the content ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Got what it takes 2 take part in the WRC Rally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Shop till u Drop, IS IT YOU, either 10K, 5K, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>1</td>\n",
       "      <td>4mths half price Orange line rental &amp; latest c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>1</td>\n",
       "      <td>Thanks for the Vote. Now sing along with the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>1</td>\n",
       "      <td>IMPORTANT INFORMATION 4 ORANGE USER 0796XXXXXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>1</td>\n",
       "      <td>Urgent! call 09066612661 from landline. Your c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>0</td>\n",
       "      <td>His frens go then he in lor. Not alone wif my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1045 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         0                Dude how do you like the buff wind.\n",
       "1         0  Tessy..pls do me a favor. Pls convey my birthd...\n",
       "2         1  Reminder: You have not downloaded the content ...\n",
       "3         1  Got what it takes 2 take part in the WRC Rally...\n",
       "4         1  Shop till u Drop, IS IT YOU, either 10K, 5K, ...\n",
       "...     ...                                                ...\n",
       "1040      1  4mths half price Orange line rental & latest c...\n",
       "1041      1  Thanks for the Vote. Now sing along with the s...\n",
       "1042      1  IMPORTANT INFORMATION 4 ORANGE USER 0796XXXXXX...\n",
       "1043      1  Urgent! call 09066612661 from landline. Your c...\n",
       "1044      0  His frens go then he in lor. Not alone wif my ...\n",
       "\n",
       "[1045 rows x 2 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8a52d581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1</td>\n",
       "      <td>Mila, age23, blonde, new in UK. I look sex wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>1</td>\n",
       "      <td>Hungry gay guys feeling hungry and up 4 it, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>0</td>\n",
       "      <td>Ugh. Gotta drive back to sd from la. My butt i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>0</td>\n",
       "      <td>Please leave this topic..sorry for telling that..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>1</td>\n",
       "      <td>We tried to contact you re our offer of New Vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>0</td>\n",
       "      <td>Hey gorgeous man. My work mobile number is. Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>0</td>\n",
       "      <td>Just sleeping..and surfing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm in solihull, | do you want anything?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>0</td>\n",
       "      <td>Jay told me already, will do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>1</td>\n",
       "      <td>U can WIN 100 of Music Gift Vouchers every we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "1045      1  Mila, age23, blonde, new in UK. I look sex wit...\n",
       "1046      1  Hungry gay guys feeling hungry and up 4 it, no...\n",
       "1047      0  Ugh. Gotta drive back to sd from la. My butt i...\n",
       "1048      0  Please leave this topic..sorry for telling that..\n",
       "1049      1  We tried to contact you re our offer of New Vi...\n",
       "...     ...                                                ...\n",
       "1189      0  Hey gorgeous man. My work mobile number is. Ha...\n",
       "1190      0                         Just sleeping..and surfing\n",
       "1191      0           I'm in solihull, | do you want anything?\n",
       "1192      0                       Jay told me already, will do\n",
       "1193      1  U can WIN 100 of Music Gift Vouchers every we...\n",
       "\n",
       "[149 rows x 2 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "5353ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>1</td>\n",
       "      <td>85233 FREE&gt;Ringtone!Reply REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>1</td>\n",
       "      <td>Ur cash-balance is currently 500 pounds - to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>1</td>\n",
       "      <td>Thanks for your ringtone order, reference numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0</td>\n",
       "      <td>We live in the next  &amp;lt;#&amp;gt; mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>1</td>\n",
       "      <td>1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1</td>\n",
       "      <td>FREE2DAY sexy St George's Day pic of Jordan!Tx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>1</td>\n",
       "      <td>Urgent! Please call 09066612661 from your land...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>1</td>\n",
       "      <td>For your chance to WIN a FREE Bluetooth Headse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>1</td>\n",
       "      <td>* FREE* POLYPHONIC RINGTONE Text SUPER to 8713...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>1</td>\n",
       "      <td>Your unique user ID is 1172. For removal send ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "1194      1                     85233 FREE>Ringtone!Reply REAL\n",
       "1195      1  Ur cash-balance is currently 500 pounds - to m...\n",
       "1196      1  Thanks for your ringtone order, reference numb...\n",
       "1197      0                We live in the next  &lt;#&gt; mins\n",
       "1198      1  1st wk FREE! Gr8 tones str8 2 u each wk. Txt N...\n",
       "...     ...                                                ...\n",
       "1489      1  FREE2DAY sexy St George's Day pic of Jordan!Tx...\n",
       "1490      1  Urgent! Please call 09066612661 from your land...\n",
       "1491      1  For your chance to WIN a FREE Bluetooth Headse...\n",
       "1492      1  * FREE* POLYPHONIC RINGTONE Text SUPER to 8713...\n",
       "1493      1  Your unique user ID is 1172. For removal send ...\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69737c2f",
   "metadata": {},
   "source": [
    "##### creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "507044a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.decode([50256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "f6e5551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length  = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"label\"]\n",
    "        return (torch.tensor(encoded, dtype=torch.long),\n",
    "                torch.tensor(label, dtype=torch.long))\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            if len(encoded_text) > max_length:\n",
    "                max_length = len(encoded_text)\n",
    "        return max_length\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "b1f4784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\"train.csv\", tokenizer, max_length=None)\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1cc4bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = SpamDataset(\"validation.csv\", tokenizer, max_length=train_dataset.max_length)\n",
    "test_dataset = SpamDataset(\"test.csv\", tokenizer, max_length=train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "2b4dfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,  \n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "087ec2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch shape: torch.Size([8, 120])\n",
      "Target batch shape: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch shape:\", input_batch.shape)\n",
    "print(\"Target batch shape:\", target_batch.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "faf8b82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0320a",
   "metadata": {},
   "source": [
    "#### Initializing model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "cc0dfb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12,},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16, },\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20, },\n",
    "    \"gpt2-xl (1.5B)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25, },\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5ae0243a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: models/124M/checkpoint\n",
      "File already exists and is up-to-date: models/124M/encoder.json\n",
      "File already exists and is up-to-date: models/124M/hparams.json\n",
      "File already exists and is up-to-date: models/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: models/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: models/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: models/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"models\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2aaad6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text with GPT-2 weights:\n",
      " Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens = 15,\n",
    "    context_size= BASE_CONFIG[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(\"Generated text with GPT-2 weights:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6ab6973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text with GPT-2 weights:\n",
      " Is the following message spam? Answer with yes or no:  'You are a winner you have been specially selected to receive a $1000 cash or a $2000 award'\n",
      "\n",
      "'You have been specially selected to receive a $1000 cash or a $2000 award' 'You have\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following message spam? Answer with yes or no: \"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive a $1000 cash or a $2000 award'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens = 23,\n",
    "    context_size= BASE_CONFIG[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(\"Generated text with GPT-2 weights:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc9edb",
   "metadata": {},
   "source": [
    "#### Adding a classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5905a684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e480479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c7ded2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(BASE_CONFIG[\"emb_dim\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "75522d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db782425",
   "metadata": {},
   "source": [
    "#### also train last transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f8ee1631",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "aefd71cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6ec84ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs shape:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b37ea00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "25bb156f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.5983,  3.9902]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:, -1, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0871378",
   "metadata": {},
   "source": [
    "#### Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "bcd014ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([[0.0005, 0.9995]])\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probabilities:\", probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "43e84104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.argmax(probas, dim=-1).item()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "17d8a296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.argmax(logits, dim=-1).item()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4251dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_prediction, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i<num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples +=predicted_labels.shape[0]\n",
    "            correct_prediction += (predicted_labels == target_batch).sum().item() \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return correct_prediction / num_examples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3bd2d015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "40f4f2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4625"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device=device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "64048755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy = calc_accuracy_loader(val_loader, model, device=device, num_batches=10)\n",
    "val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "d9a94338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4875"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "ab40b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits,target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "643d88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "2203f023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.902580827474594"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss = calc_loss_loader(train_loader, model, device, num_batches=10)\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "84028751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8360012769699097"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss = calc_loss_loader(val_loader, model, device, num_batches=10)\n",
    "val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b280ceec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6336533665657043"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss = calc_loss_loader(test_loader, model, device, num_batches=10)\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da7b0e",
   "metadata": {},
   "source": [
    "#### Fine tuning model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b48c3a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                model.eval()\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Epoch {epoch+1}, Step {global_step:06d}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        \n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e95c20ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "07edd168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 000000: Train Loss = 2.1534, Val Loss = 2.3919\n",
      "Epoch 1, Step 000050: Train Loss = 0.6170, Val Loss = 0.6371\n",
      "Epoch 1, Step 000100: Train Loss = 0.5231, Val Loss = 0.5574\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Epoch 2, Step 000150: Train Loss = 0.5605, Val Loss = 0.4886\n",
      "Epoch 2, Step 000200: Train Loss = 0.4190, Val Loss = 0.3966\n",
      "Epoch 2, Step 000250: Train Loss = 0.4089, Val Loss = 0.3531\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Epoch 3, Step 000300: Train Loss = 0.3334, Val Loss = 0.3204\n",
      "Epoch 3, Step 000350: Train Loss = 0.3400, Val Loss = 0.3062\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Epoch 4, Step 000400: Train Loss = 0.1363, Val Loss = 0.2001\n",
      "Epoch 4, Step 000450: Train Loss = 0.1531, Val Loss = 0.1322\n",
      "Epoch 4, Step 000500: Train Loss = 0.2224, Val Loss = 0.1366\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Epoch 5, Step 000550: Train Loss = 0.2066, Val Loss = 0.1434\n",
      "Epoch 5, Step 000600: Train Loss = 0.0832, Val Loss = 0.0736\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 4.66 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=50, eval_iter=5)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a4343643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples Seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    os.makedirs(\"figures\", exist_ok=True)\n",
    "    plt.savefig(f\"figures/{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "fa641dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "13f2f6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "08e0e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3034d",
   "metadata": {},
   "source": [
    "#### Using LLM as spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "15f83e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_ids = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "bbf279e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive a $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_text(text_1, model, tokenizer, device, max_length = train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f91e17f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\"Hey, just wanted to check if we're still on\"\n",
    "          \"for dinner tonight? Let me know!\")\n",
    "\n",
    "print(classify_text(text_2, model, tokenizer, device, max_length = train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9fb1e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/spam_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d7eac024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"models/spam_classifier.pth\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d82d9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661136da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
